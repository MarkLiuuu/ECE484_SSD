{"cells":[{"cell_type":"markdown","metadata":{"id":"QUANWN3rpfC9"},"source":["# Get Info (If Using Colab)"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":255,"status":"ok","timestamp":1650657122619,"user":{"displayName":"NNM_","userId":"18288667490642199446"},"user_tz":240},"id":"8U1nSSnI5AyR","outputId":"cbd99b56-fdb8-4c7c-bd8f-cc315a9b71ef"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Apr 22 19:52:03 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   54C    P0    33W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7604,"status":"ok","timestamp":1650657132379,"user":{"displayName":"NNM_","userId":"18288667490642199446"},"user_tz":240},"id":"x8uvO83jqnhA","outputId":"d382fdb9-f071-4bbe-9f0a-33d1bc36dcbf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found GPU at: /device:GPU:0\n"]}],"source":["import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1650657132379,"user":{"displayName":"NNM_","userId":"18288667490642199446"},"user_tz":240},"id":"NFg6zVA05XBx","outputId":"63e7b13f-267f-4004-aaf5-1085faefbc88"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.8.0\n"]}],"source":["print(tf.__version__)"]},{"cell_type":"markdown","metadata":{"id":"y_EY6pnL5xzW"},"source":["# 0. Set up Paths for all Directories"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1650657132380,"user":{"displayName":"NNM_","userId":"18288667490642199446"},"user_tz":240},"id":"146BB11JpfDA"},"outputs":[],"source":["# only has \"labelimg\" and \"workspace\" folder under tfod\n","# only has \"images\" folder under \"workspace\"\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"42hJEdo_pfDB"},"outputs":[],"source":["# CUSTOM_MODEL_NAME = 'my_ssd_mobnet_640' \n","# PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8'\n","# PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz'\n","# TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n","# LABEL_MAP_NAME = 'label_map.pbtxt'"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1650657132380,"user":{"displayName":"NNM_","userId":"18288667490642199446"},"user_tz":240},"id":"-dqNEubSktO2"},"outputs":[],"source":["# including original training samples\n","CUSTOM_MODEL_NAME = 'my_ssd_mobilnet_v2' \n","PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8'\n","PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz'\n","TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n","LABEL_MAP_NAME = 'label_map.pbtxt'"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1650657132380,"user":{"displayName":"NNM_","userId":"18288667490642199446"},"user_tz":240},"id":"hbPhYVy_pfDB"},"outputs":[],"source":["paths = {\n","    'WORKSPACE_PATH': os.path.join('tfod', 'workspace'),\n","    'SCRIPTS_PATH': os.path.join('tfod','scripts'),\n","    'APIMODEL_PATH': os.path.join('tfod','models'),\n","    'ANNOTATION_PATH': os.path.join('tfod', 'workspace','annotations'),\n","    'IMAGE_PATH': os.path.join('tfod', 'workspace','images'),\n","    'MODEL_PATH': os.path.join('tfod', 'workspace','models'),\n","    'PRETRAINED_MODEL_PATH': os.path.join('tfod', 'workspace','pre-trained-models'),\n","    'CHECKPOINT_PATH': os.path.join('tfod', 'workspace','models',CUSTOM_MODEL_NAME), \n","    'OUTPUT_PATH': os.path.join('tfod', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n","    'TFJS_PATH':os.path.join('tfod', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n","    'TFLITE_PATH':os.path.join('tfod', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n","    'PROTOC_PATH':os.path.join('tfod','protoc')\n"," }"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1650657132381,"user":{"displayName":"NNM_","userId":"18288667490642199446"},"user_tz":240},"id":"LwhWZMI0pfDC"},"outputs":[],"source":["files = {\n","    'PIPELINE_CONFIG':os.path.join('tfod', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n","    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n","    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n","}"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":1588,"status":"ok","timestamp":1650657133962,"user":{"displayName":"NNM_","userId":"18288667490642199446"},"user_tz":240},"id":"HR-TfDGrpfDC"},"outputs":[],"source":["for path in paths.values():\n","    if not os.path.exists(path):\n","        if os.name == 'posix':\n","            !mkdir -p {path}\n","        if os.name == 'nt':\n","            !mkdir {path}"]},{"cell_type":"markdown","metadata":{"id":"OLU-rs_ipfDE"},"source":["# 1. Download TF Models Pretrained Models from Tensorflow Model Zoo and Install TFOD"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IgFtjt5CktO4"},"outputs":[],"source":["# https://www.tensorflow.org/install/source_windows"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K-Cmz2edpfDE","scrolled":true},"outputs":[],"source":["# if os.name=='nt':\n","#     !pip install wget\n","#     import wget"]},{"cell_type":"markdown","metadata":{"id":"A65U5LLh5xzZ"},"source":["### SKIP if TFOD API already cloned from Git"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53671,"status":"ok","timestamp":1650657187877,"user":{"displayName":"NNM_","userId":"18288667490642199446"},"user_tz":240},"id":"iA1DIq5OpfDE","outputId":"53d67e1c-2e32-4ec3-8670-a83e899ad839"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'tfod/models'...\n","remote: Enumerating objects: 72121, done.\u001b[K\n","remote: Counting objects: 100% (36/36), done.\u001b[K\n","remote: Compressing objects: 100% (29/29), done.\u001b[K\n","remote: Total 72121 (delta 13), reused 23 (delta 6), pack-reused 72085\u001b[K\n","Receiving objects: 100% (72121/72121), 578.97 MiB | 11.97 MiB/s, done.\n","Resolving deltas: 100% (51017/51017), done.\n"]}],"source":["if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n","    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"]},{"cell_type":"markdown","metadata":{"id":"VUl5_UFik7w5"},"source":["### Add the follwing if in Colab\n","#### May no longer needed when TFOD API upgraded to 2.8.0 in the future\n","\n","'tensorflow==2.7.0',\n","\n","'tf-models-official==2.7.0',\n","\n","'tensorflow_io==0.23.1',"]},{"cell_type":"markdown","metadata":{"id":"LfRcuJro5xzb"},"source":["### SKIP, if TFOD API is already installed "]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48945,"status":"ok","timestamp":1650657236812,"user":{"displayName":"NNM_","userId":"18288667490642199446"},"user_tz":240},"id":"rJjMHbnDs3Tv","outputId":"0be74caf-0e13-4e93-8e42-00a09edfb5c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n","0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n","Processing /content/tfod/models/research\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","Collecting avro-python3\n","  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n","Collecting apache-beam\n","  Downloading apache_beam-2.38.0-cp37-cp37m-manylinux2010_x86_64.whl (10.2 MB)\n","\u001b[K     |████████████████████████████████| 10.2 MB 6.6 MB/s \n","\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.28)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n","Collecting tf-slim\n","  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n","\u001b[K     |████████████████████████████████| 352 kB 49.6 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.4)\n","Collecting lvis\n","  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n","Collecting tf-models-official>=2.5.1\n","  Downloading tf_models_official-2.8.0-py2.py3-none-any.whl (2.2 MB)\n","\u001b[K     |████████████████████████████████| 2.2 MB 38.8 MB/s \n","\u001b[?25hCollecting tensorflow_io\n","  Downloading tensorflow_io-0.25.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.4 MB)\n","\u001b[K     |████████████████████████████████| 23.4 MB 1.4 MB/s \n","\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.8.0)\n","Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n","Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n","Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 40.2 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow~=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.8.0)\n","Collecting pyyaml<6.0,>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 48.9 MB/s \n","\u001b[?25hCollecting sacrebleu\n","  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n","\u001b[K     |████████████████████████████████| 90 kB 10.4 MB/s \n","\u001b[?25hCollecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 1.9 MB/s \n","\u001b[?25hCollecting opencv-python-headless\n","  Downloading opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n","\u001b[K     |████████████████████████████████| 47.8 MB 1.6 MB/s \n","\u001b[?25hRequirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.11)\n","Collecting py-cpuinfo>=3.3.0\n","  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n","\u001b[K     |████████████████████████████████| 99 kB 7.3 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n","Collecting tensorflow-text~=2.8.0\n","  Downloading tensorflow_text-2.8.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n","\u001b[K     |████████████████████████████████| 4.9 MB 33.8 MB/s \n","\u001b[?25hCollecting tensorflow-addons\n","  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 44.1 MB/s \n","\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n","  Downloading tensorflow_model_optimization-0.7.2-py2.py3-none-any.whl (237 kB)\n","\u001b[K     |████████████████████████████████| 237 kB 37.5 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n","Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.21.6)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n","Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n","Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.31.5)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.56.0)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2022.1)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.10.8)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.8)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.8.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.44.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.24.0)\n","Collecting tf-estimator-nightly==2.8.0.dev2021122109\n","  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n","\u001b[K     |████████████████████████████████| 462 kB 37.7 MB/s \n","\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.5.3)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (13.0.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.8.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n","Collecting requests<3.0.0dev,>=2.18.0\n","  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n","\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n","  Downloading dill-0.3.1.1.tar.gz (151 kB)\n","\u001b[K     |████████████████████████████████| 151 kB 53.2 MB/s \n","\u001b[?25hCollecting pymongo<4.0.0,>=3.8.0\n","  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n","\u001b[K     |████████████████████████████████| 508 kB 50.8 MB/s \n","\u001b[?25hRequirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n","Collecting orjson<4.0\n","  Downloading orjson-3.6.8-cp37-cp37m-manylinux_2_24_x86_64.whl (253 kB)\n","\u001b[K     |████████████████████████████████| 253 kB 49.0 MB/s \n","\u001b[?25hRequirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n","Collecting proto-plus<2,>=1.7.1\n","  Downloading proto_plus-1.20.3-py3-none-any.whl (46 kB)\n","\u001b[K     |████████████████████████████████| 46 kB 4.3 MB/s \n","\u001b[?25hCollecting cloudpickle<3,>=2.0.0\n","  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n","Collecting fastavro<2,>=0.23.6\n","  Downloading fastavro-1.4.10-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n","\u001b[K     |████████████████████████████████| 2.3 MB 40.6 MB/s \n","\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n","  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n","Requirement already satisfied: pyarrow<7.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n","Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n","Collecting protobuf>=3.12.0\n","  Downloading protobuf-3.20.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n","\u001b[K     |████████████████████████████████| 1.0 MB 44.6 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.12)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.4.2)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n","Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2019.12.20)\n","Collecting portalocker\n","  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.7.0)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.7.0)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.4.0)\n","Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.16.0)\n","Collecting tensorflow-io-gcs-filesystem>=0.23.1\n","  Downloading tensorflow_io_gcs_filesystem-0.25.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n","\u001b[K     |████████████████████████████████| 2.1 MB 35.6 MB/s \n","\u001b[?25hBuilding wheels for collected packages: object-detection, py-cpuinfo, dill, avro-python3, seqeval\n","  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1691106 sha256=8ce510b13671f047a9940054efa2f6b7a8e7a347d814b4af9faaf695aaadabf7\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-jn1fc4qk/wheels/d6/44/bc/97e57adf98cf36bb2260739c10dc1db9909c085382ed203145\n","  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=daaa417c30f66265d531ca27e9f69eb44b928c0c14d4417860cf028badeaad23\n","  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n","  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=cb9c7e5237ae255a393d7f5d0f004ee3f513db5728a46ae797322e64e7e05686\n","  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n","  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=fe61da601ca29db5dfd33e70d5ad3ec15c31651a1b7465e34fc2e6efdf9e2271\n","  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=ee3a46e463e79a814326dd59e0fd91d4716098b5aae7235e5d82d21595f74dbd\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built object-detection py-cpuinfo dill avro-python3 seqeval\n","Installing collected packages: requests, protobuf, tf-estimator-nightly, tensorflow-io-gcs-filesystem, portalocker, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, proto-plus, orjson, opencv-python-headless, hdfs, fastavro, cloudpickle, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.17.3\n","    Uninstalling protobuf-3.17.3:\n","      Successfully uninstalled protobuf-3.17.3\n","  Attempting uninstall: tensorflow-io-gcs-filesystem\n","    Found existing installation: tensorflow-io-gcs-filesystem 0.24.0\n","    Uninstalling tensorflow-io-gcs-filesystem-0.24.0:\n","      Successfully uninstalled tensorflow-io-gcs-filesystem-0.24.0\n","  Attempting uninstall: dill\n","    Found existing installation: dill 0.3.4\n","    Uninstalling dill-0.3.4:\n","      Successfully uninstalled dill-0.3.4\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: pymongo\n","    Found existing installation: pymongo 4.1.1\n","    Uninstalling pymongo-4.1.1:\n","      Successfully uninstalled pymongo-4.1.1\n","  Attempting uninstall: cloudpickle\n","    Found existing installation: cloudpickle 1.3.0\n","    Uninstalling cloudpickle-1.3.0:\n","      Successfully uninstalled cloudpickle-1.3.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n","gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed apache-beam-2.38.0 avro-python3-1.10.2 cloudpickle-2.0.0 colorama-0.4.4 dill-0.3.1.1 fastavro-1.4.10 hdfs-2.7.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.5.64 orjson-3.6.8 portalocker-2.4.0 proto-plus-1.20.3 protobuf-3.20.1 py-cpuinfo-8.0.0 pymongo-3.12.3 pyyaml-5.4.1 requests-2.27.1 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.16.1 tensorflow-io-0.25.0 tensorflow-io-gcs-filesystem-0.25.0 tensorflow-model-optimization-0.7.2 tensorflow-text-2.8.2 tf-estimator-nightly-2.8.0.dev2021122109 tf-models-official-2.8.0 tf-slim-1.1.0\n"]}],"source":["# Install Tensorflow Object Detection \n","if os.name=='posix':  \n","    !apt-get install protobuf-compiler\n","    !cd tfod/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n","    \n","if os.name=='nt':\n","    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n","    wget.download(url)\n","    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n","    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n","    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n","    !cd tfod/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n","    !cd tfod/models/research/slim && pip install -e . "]},{"cell_type":"markdown","metadata":{"id":"dkdFNq8N5xzc"},"source":["### Verify TFOD API is correctly installed"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38368,"status":"ok","timestamp":1650657284270,"user":{"displayName":"NNM_","userId":"18288667490642199446"},"user_tz":240},"id":"TmKo_tv-ktO7","outputId":"970a3513-8d84-45de-bafb-f13b41e3482a","scrolled":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Running tests under Python 3.7.13: /usr/bin/python3\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","2022-04-22 19:54:11.408790: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","W0422 19:54:11.736160 139929959282560 model_builder.py:1102] Building experimental DeepMAC meta-arch. Some features may be omitted.\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.53s\n","I0422 19:54:12.206923 139929959282560 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.53s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.63s\n","I0422 19:54:12.834534 139929959282560 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.63s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.34s\n","I0422 19:54:13.178728 139929959282560 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.34s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.31s\n","I0422 19:54:13.492469 139929959282560 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.31s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.47s\n","I0422 19:54:15.965846 139929959282560 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.47s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","I0422 19:54:15.966968 139929959282560 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n","I0422 19:54:15.995379 139929959282560 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n","I0422 19:54:16.013645 139929959282560 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n","I0422 19:54:16.031576 139929959282560 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.12s\n","I0422 19:54:16.149286 139929959282560 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.12s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.11s\n","I0422 19:54:16.262285 139929959282560 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.11s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.13s\n","I0422 19:54:16.389580 139929959282560 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.13s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.13s\n","I0422 19:54:16.518993 139929959282560 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.13s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.13s\n","I0422 19:54:16.650266 139929959282560 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.13s\n","[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n","I0422 19:54:16.686284 139929959282560 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","I0422 19:54:16.912482 139929959282560 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I0422 19:54:16.912724 139929959282560 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n","I0422 19:54:16.912830 139929959282560 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n","I0422 19:54:16.915569 139929959282560 efficientnet_model.py:144] round_filter input=32 output=32\n","I0422 19:54:16.935473 139929959282560 efficientnet_model.py:144] round_filter input=32 output=32\n","I0422 19:54:16.935623 139929959282560 efficientnet_model.py:144] round_filter input=16 output=16\n","I0422 19:54:17.007715 139929959282560 efficientnet_model.py:144] round_filter input=16 output=16\n","I0422 19:54:17.007887 139929959282560 efficientnet_model.py:144] round_filter input=24 output=24\n","I0422 19:54:17.195712 139929959282560 efficientnet_model.py:144] round_filter input=24 output=24\n","I0422 19:54:17.195919 139929959282560 efficientnet_model.py:144] round_filter input=40 output=40\n","I0422 19:54:17.378165 139929959282560 efficientnet_model.py:144] round_filter input=40 output=40\n","I0422 19:54:17.378399 139929959282560 efficientnet_model.py:144] round_filter input=80 output=80\n","I0422 19:54:17.680065 139929959282560 efficientnet_model.py:144] round_filter input=80 output=80\n","I0422 19:54:17.680291 139929959282560 efficientnet_model.py:144] round_filter input=112 output=112\n","I0422 19:54:17.971666 139929959282560 efficientnet_model.py:144] round_filter input=112 output=112\n","I0422 19:54:17.971862 139929959282560 efficientnet_model.py:144] round_filter input=192 output=192\n","I0422 19:54:18.531262 139929959282560 efficientnet_model.py:144] round_filter input=192 output=192\n","I0422 19:54:18.531480 139929959282560 efficientnet_model.py:144] round_filter input=320 output=320\n","I0422 19:54:18.632361 139929959282560 efficientnet_model.py:144] round_filter input=1280 output=1280\n","I0422 19:54:18.668222 139929959282560 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0422 19:54:18.731977 139929959282560 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\n","I0422 19:54:18.732198 139929959282560 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n","I0422 19:54:18.732299 139929959282560 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\n","I0422 19:54:18.734290 139929959282560 efficientnet_model.py:144] round_filter input=32 output=32\n","I0422 19:54:18.751965 139929959282560 efficientnet_model.py:144] round_filter input=32 output=32\n","I0422 19:54:18.752082 139929959282560 efficientnet_model.py:144] round_filter input=16 output=16\n","I0422 19:54:18.899991 139929959282560 efficientnet_model.py:144] round_filter input=16 output=16\n","I0422 19:54:18.900213 139929959282560 efficientnet_model.py:144] round_filter input=24 output=24\n","I0422 19:54:19.170848 139929959282560 efficientnet_model.py:144] round_filter input=24 output=24\n","I0422 19:54:19.171109 139929959282560 efficientnet_model.py:144] round_filter input=40 output=40\n","I0422 19:54:19.455596 139929959282560 efficientnet_model.py:144] round_filter input=40 output=40\n","I0422 19:54:19.455812 139929959282560 efficientnet_model.py:144] round_filter input=80 output=80\n","I0422 19:54:19.821684 139929959282560 efficientnet_model.py:144] round_filter input=80 output=80\n","I0422 19:54:19.821925 139929959282560 efficientnet_model.py:144] round_filter input=112 output=112\n","I0422 19:54:20.179943 139929959282560 efficientnet_model.py:144] round_filter input=112 output=112\n","I0422 19:54:20.180143 139929959282560 efficientnet_model.py:144] round_filter input=192 output=192\n","I0422 19:54:20.638772 139929959282560 efficientnet_model.py:144] round_filter input=192 output=192\n","I0422 19:54:20.638997 139929959282560 efficientnet_model.py:144] round_filter input=320 output=320\n","I0422 19:54:20.824064 139929959282560 efficientnet_model.py:144] round_filter input=1280 output=1280\n","I0422 19:54:20.858843 139929959282560 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0422 19:54:20.936151 139929959282560 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2\n","I0422 19:54:20.936355 139929959282560 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n","I0422 19:54:20.936469 139929959282560 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5\n","I0422 19:54:20.938376 139929959282560 efficientnet_model.py:144] round_filter input=32 output=32\n","I0422 19:54:20.956030 139929959282560 efficientnet_model.py:144] round_filter input=32 output=32\n","I0422 19:54:20.956200 139929959282560 efficientnet_model.py:144] round_filter input=16 output=16\n","I0422 19:54:21.093875 139929959282560 efficientnet_model.py:144] round_filter input=16 output=16\n","I0422 19:54:21.094062 139929959282560 efficientnet_model.py:144] round_filter input=24 output=24\n","I0422 19:54:21.369812 139929959282560 efficientnet_model.py:144] round_filter input=24 output=24\n","I0422 19:54:21.370031 139929959282560 efficientnet_model.py:144] round_filter input=40 output=48\n","I0422 19:54:21.643946 139929959282560 efficientnet_model.py:144] round_filter input=40 output=48\n","I0422 19:54:21.644150 139929959282560 efficientnet_model.py:144] round_filter input=80 output=88\n","I0422 19:54:22.017538 139929959282560 efficientnet_model.py:144] round_filter input=80 output=88\n","I0422 19:54:22.017752 139929959282560 efficientnet_model.py:144] round_filter input=112 output=120\n","I0422 19:54:22.397134 139929959282560 efficientnet_model.py:144] round_filter input=112 output=120\n","I0422 19:54:22.397446 139929959282560 efficientnet_model.py:144] round_filter input=192 output=208\n","I0422 19:54:22.896500 139929959282560 efficientnet_model.py:144] round_filter input=192 output=208\n","I0422 19:54:22.896704 139929959282560 efficientnet_model.py:144] round_filter input=320 output=352\n","I0422 19:54:23.078702 139929959282560 efficientnet_model.py:144] round_filter input=1280 output=1408\n","I0422 19:54:23.116357 139929959282560 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0422 19:54:23.187333 139929959282560 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3\n","I0422 19:54:23.187547 139929959282560 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n","I0422 19:54:23.187656 139929959282560 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6\n","I0422 19:54:23.189752 139929959282560 efficientnet_model.py:144] round_filter input=32 output=40\n","I0422 19:54:23.207992 139929959282560 efficientnet_model.py:144] round_filter input=32 output=40\n","I0422 19:54:23.208130 139929959282560 efficientnet_model.py:144] round_filter input=16 output=24\n","I0422 19:54:23.624857 139929959282560 efficientnet_model.py:144] round_filter input=16 output=24\n","I0422 19:54:23.625070 139929959282560 efficientnet_model.py:144] round_filter input=24 output=32\n","I0422 19:54:23.906934 139929959282560 efficientnet_model.py:144] round_filter input=24 output=32\n","I0422 19:54:23.907144 139929959282560 efficientnet_model.py:144] round_filter input=40 output=48\n","I0422 19:54:24.177677 139929959282560 efficientnet_model.py:144] round_filter input=40 output=48\n","I0422 19:54:24.177952 139929959282560 efficientnet_model.py:144] round_filter input=80 output=96\n","I0422 19:54:24.644291 139929959282560 efficientnet_model.py:144] round_filter input=80 output=96\n","I0422 19:54:24.644516 139929959282560 efficientnet_model.py:144] round_filter input=112 output=136\n","I0422 19:54:25.115754 139929959282560 efficientnet_model.py:144] round_filter input=112 output=136\n","I0422 19:54:25.115947 139929959282560 efficientnet_model.py:144] round_filter input=192 output=232\n","I0422 19:54:25.679205 139929959282560 efficientnet_model.py:144] round_filter input=192 output=232\n","I0422 19:54:25.679427 139929959282560 efficientnet_model.py:144] round_filter input=320 output=384\n","I0422 19:54:25.869262 139929959282560 efficientnet_model.py:144] round_filter input=1280 output=1536\n","I0422 19:54:25.904411 139929959282560 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0422 19:54:25.984075 139929959282560 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\n","I0422 19:54:25.984257 139929959282560 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n","I0422 19:54:25.984352 139929959282560 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n","I0422 19:54:25.986468 139929959282560 efficientnet_model.py:144] round_filter input=32 output=48\n","I0422 19:54:26.006056 139929959282560 efficientnet_model.py:144] round_filter input=32 output=48\n","I0422 19:54:26.006211 139929959282560 efficientnet_model.py:144] round_filter input=16 output=24\n","I0422 19:54:26.146320 139929959282560 efficientnet_model.py:144] round_filter input=16 output=24\n","I0422 19:54:26.146576 139929959282560 efficientnet_model.py:144] round_filter input=24 output=32\n","I0422 19:54:26.505455 139929959282560 efficientnet_model.py:144] round_filter input=24 output=32\n","I0422 19:54:26.505680 139929959282560 efficientnet_model.py:144] round_filter input=40 output=56\n","I0422 19:54:26.878789 139929959282560 efficientnet_model.py:144] round_filter input=40 output=56\n","I0422 19:54:26.879025 139929959282560 efficientnet_model.py:144] round_filter input=80 output=112\n","I0422 19:54:27.428314 139929959282560 efficientnet_model.py:144] round_filter input=80 output=112\n","I0422 19:54:27.428538 139929959282560 efficientnet_model.py:144] round_filter input=112 output=160\n","I0422 19:54:28.007025 139929959282560 efficientnet_model.py:144] round_filter input=112 output=160\n","I0422 19:54:28.007241 139929959282560 efficientnet_model.py:144] round_filter input=192 output=272\n","I0422 19:54:28.755631 139929959282560 efficientnet_model.py:144] round_filter input=192 output=272\n","I0422 19:54:28.755873 139929959282560 efficientnet_model.py:144] round_filter input=320 output=448\n","I0422 19:54:28.948921 139929959282560 efficientnet_model.py:144] round_filter input=1280 output=1792\n","I0422 19:54:28.984128 139929959282560 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0422 19:54:29.318069 139929959282560 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5\n","I0422 19:54:29.318299 139929959282560 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n","I0422 19:54:29.318421 139929959282560 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n","I0422 19:54:29.320531 139929959282560 efficientnet_model.py:144] round_filter input=32 output=48\n","I0422 19:54:29.344299 139929959282560 efficientnet_model.py:144] round_filter input=32 output=48\n","I0422 19:54:29.344498 139929959282560 efficientnet_model.py:144] round_filter input=16 output=24\n","I0422 19:54:29.564460 139929959282560 efficientnet_model.py:144] round_filter input=16 output=24\n","I0422 19:54:29.564704 139929959282560 efficientnet_model.py:144] round_filter input=24 output=40\n","I0422 19:54:30.058609 139929959282560 efficientnet_model.py:144] round_filter input=24 output=40\n","I0422 19:54:30.058795 139929959282560 efficientnet_model.py:144] round_filter input=40 output=64\n","I0422 19:54:30.518104 139929959282560 efficientnet_model.py:144] round_filter input=40 output=64\n","I0422 19:54:30.518343 139929959282560 efficientnet_model.py:144] round_filter input=80 output=128\n","I0422 19:54:31.163203 139929959282560 efficientnet_model.py:144] round_filter input=80 output=128\n","I0422 19:54:31.163439 139929959282560 efficientnet_model.py:144] round_filter input=112 output=176\n","I0422 19:54:31.837493 139929959282560 efficientnet_model.py:144] round_filter input=112 output=176\n","I0422 19:54:31.837718 139929959282560 efficientnet_model.py:144] round_filter input=192 output=304\n","I0422 19:54:32.695379 139929959282560 efficientnet_model.py:144] round_filter input=192 output=304\n","I0422 19:54:32.695613 139929959282560 efficientnet_model.py:144] round_filter input=320 output=512\n","I0422 19:54:32.982247 139929959282560 efficientnet_model.py:144] round_filter input=1280 output=2048\n","I0422 19:54:33.016812 139929959282560 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0422 19:54:33.118432 139929959282560 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6\n","I0422 19:54:33.118716 139929959282560 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n","I0422 19:54:33.118811 139929959282560 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n","I0422 19:54:33.120917 139929959282560 efficientnet_model.py:144] round_filter input=32 output=56\n","I0422 19:54:33.140550 139929959282560 efficientnet_model.py:144] round_filter input=32 output=56\n","I0422 19:54:33.140714 139929959282560 efficientnet_model.py:144] round_filter input=16 output=32\n","I0422 19:54:33.362165 139929959282560 efficientnet_model.py:144] round_filter input=16 output=32\n","I0422 19:54:33.362410 139929959282560 efficientnet_model.py:144] round_filter input=24 output=40\n","I0422 19:54:33.920524 139929959282560 efficientnet_model.py:144] round_filter input=24 output=40\n","I0422 19:54:33.920727 139929959282560 efficientnet_model.py:144] round_filter input=40 output=72\n","I0422 19:54:34.472247 139929959282560 efficientnet_model.py:144] round_filter input=40 output=72\n","I0422 19:54:34.472532 139929959282560 efficientnet_model.py:144] round_filter input=80 output=144\n","I0422 19:54:35.212938 139929959282560 efficientnet_model.py:144] round_filter input=80 output=144\n","I0422 19:54:35.213135 139929959282560 efficientnet_model.py:144] round_filter input=112 output=200\n","I0422 19:54:36.298595 139929959282560 efficientnet_model.py:144] round_filter input=112 output=200\n","I0422 19:54:36.298802 139929959282560 efficientnet_model.py:144] round_filter input=192 output=344\n","I0422 19:54:37.328969 139929959282560 efficientnet_model.py:144] round_filter input=192 output=344\n","I0422 19:54:37.329206 139929959282560 efficientnet_model.py:144] round_filter input=320 output=576\n","I0422 19:54:37.612222 139929959282560 efficientnet_model.py:144] round_filter input=1280 output=2304\n","I0422 19:54:37.646639 139929959282560 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0422 19:54:37.762897 139929959282560 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7\n","I0422 19:54:37.763107 139929959282560 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n","I0422 19:54:37.763217 139929959282560 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n","I0422 19:54:37.765106 139929959282560 efficientnet_model.py:144] round_filter input=32 output=64\n","I0422 19:54:37.783449 139929959282560 efficientnet_model.py:144] round_filter input=32 output=64\n","I0422 19:54:37.783590 139929959282560 efficientnet_model.py:144] round_filter input=16 output=32\n","I0422 19:54:38.084572 139929959282560 efficientnet_model.py:144] round_filter input=16 output=32\n","I0422 19:54:38.084784 139929959282560 efficientnet_model.py:144] round_filter input=24 output=48\n","I0422 19:54:38.741034 139929959282560 efficientnet_model.py:144] round_filter input=24 output=48\n","I0422 19:54:38.741254 139929959282560 efficientnet_model.py:144] round_filter input=40 output=80\n","I0422 19:54:39.411184 139929959282560 efficientnet_model.py:144] round_filter input=40 output=80\n","I0422 19:54:39.411393 139929959282560 efficientnet_model.py:144] round_filter input=80 output=160\n","I0422 19:54:40.325739 139929959282560 efficientnet_model.py:144] round_filter input=80 output=160\n","I0422 19:54:40.325986 139929959282560 efficientnet_model.py:144] round_filter input=112 output=224\n","I0422 19:54:41.249877 139929959282560 efficientnet_model.py:144] round_filter input=112 output=224\n","I0422 19:54:41.250092 139929959282560 efficientnet_model.py:144] round_filter input=192 output=384\n","I0422 19:54:42.435442 139929959282560 efficientnet_model.py:144] round_filter input=192 output=384\n","I0422 19:54:42.435723 139929959282560 efficientnet_model.py:144] round_filter input=320 output=640\n","I0422 19:54:43.127020 139929959282560 efficientnet_model.py:144] round_filter input=1280 output=2560\n","I0422 19:54:43.167657 139929959282560 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 26.62s\n","I0422 19:54:43.305832 139929959282560 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 26.62s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","I0422 19:54:43.313517 139929959282560 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","I0422 19:54:43.315251 139929959282560 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","I0422 19:54:43.315805 139929959282560 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","I0422 19:54:43.317457 139929959282560 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","[ RUN      ] ModelBuilderTF2Test.test_session\n","[  SKIPPED ] ModelBuilderTF2Test.test_session\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","I0422 19:54:43.319130 139929959282560 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","I0422 19:54:43.319646 139929959282560 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","I0422 19:54:43.320790 139929959282560 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","----------------------------------------------------------------------\n","Ran 24 tests in 32.641s\n","\n","OK (skipped=1)\n"]}],"source":["VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n","# Verify Installation\n","!python {VERIFICATION_SCRIPT}"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"NVbf4VnMktO7"},"outputs":[],"source":["# !pip install tensorflow --upgrade"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"3dcxOe4gktO7"},"outputs":[],"source":["# !pip uninstall protobuf matplotlib -y\n","# !pip install protobuf matplotlib==3.2"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1650657284270,"user":{"displayName":"NNM_","userId":"18288667490642199446"},"user_tz":240},"id":"_SNXTRVIktO7"},"outputs":[],"source":["import object_detection"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rNI56vNhktO8","scrolled":true},"outputs":[],"source":["# !pip list"]},{"cell_type":"markdown","metadata":{"id":"C2oV2LLX5xzd"},"source":["## SKIP, if pretrained model is downloaded already, or\n","## if using exported model from other places"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":849,"status":"ok","timestamp":1650637700784,"user":{"displayName":"NNM_","userId":"18288667490642199446"},"user_tz":240},"id":"csofht2npfDE","outputId":"db7f4b8a-2581-42e3-9295-2fa56bb27b2d"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-04-22 14:28:20--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz\n","Resolving download.tensorflow.org (download.tensorflow.org)... 142.251.33.208, 2607:f8b0:4004:837::2010\n","Connecting to download.tensorflow.org (download.tensorflow.org)|142.251.33.208|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 20518283 (20M) [application/x-tar]\n","Saving to: ‘ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz’\n","\n","ssd_mobilenet_v2_fp 100%[===================>]  19.57M  --.-KB/s    in 0.1s    \n","\n","2022-04-22 14:28:20 (175 MB/s) - ‘ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz’ saved [20518283/20518283]\n","\n","ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/\n","ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/\n","ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n","ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/checkpoint\n","ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n","ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/pipeline.config\n","ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/\n","ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/saved_model.pb\n","ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/\n","ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n","ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"]}],"source":["if os.name =='posix':\n","    !wget {PRETRAINED_MODEL_URL}\n","    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n","    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n","if os.name == 'nt':\n","    wget.download(PRETRAINED_MODEL_URL)\n","    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n","    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"]},{"cell_type":"markdown","metadata":{"id":"M5KJTnkfpfDC"},"source":["# 2. Create Label Map"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2YFV3Mppqip_","executionInfo":{"status":"ok","timestamp":1650637723198,"user_tz":240,"elapsed":12855,"user":{"displayName":"NNM_","userId":"18288667490642199446"}},"outputId":"1d3a684a-4046-4566-ad69-c49678df9296"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":151,"status":"ok","timestamp":1650637724971,"user":{"displayName":"NNM_","userId":"18288667490642199446"},"user_tz":240},"id":"p1BVDWo7pfDC"},"outputs":[],"source":["labels = [{'name':'High 5', 'id':1}, {'name':'Point Up', 'id':2}, \n","          {'name':'Point Down', 'id':3}, {'name':'Good', 'id':4},\n","          {'name':'Point Right', 'id':5}, {'name':'Point Left', 'id':6}]\n","\n","with open(files['LABELMAP'], 'w') as f:\n","    for label in labels:\n","        f.write('item { \\n')\n","        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n","        f.write('\\tid:{}\\n'.format(label['id']))\n","        f.write('}\\n')"]},{"cell_type":"markdown","metadata":{"id":"C88zyVELpfDC"},"source":["# 3. Create TF records (SKIP if not training, or evaluate metrics)"]},{"cell_type":"markdown","metadata":{"id":"EAeEy3PQuZ-D"},"source":["## upload archived images to image path"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":139,"status":"ok","timestamp":1650637733030,"user":{"displayName":"NNM_","userId":"18288667490642199446"},"user_tz":240},"id":"StbwFWCU7WP8","outputId":"30195545-ba21-4420-e42e-27df5fa50ee0"},"outputs":[{"output_type":"stream","name":"stdout","text":["tfod/workspace/images\n"]}],"source":["print(paths['IMAGE_PATH'])"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":290,"status":"ok","timestamp":1650637734403,"user":{"displayName":"NNM_","userId":"18288667490642199446"},"user_tz":240},"id":"kvf5WccwrFGq","outputId":"7c5a1054-cb12-45d0-f358-3520289966be"},"outputs":[{"output_type":"stream","name":"stdout","text":["tfod/workspace/images/train/\n","tfod/workspace/images/train/Good_7.xml\n","tfod/workspace/images/train/Good_1.jpg\n","tfod/workspace/images/train/Good_1.xml\n","tfod/workspace/images/train/Good_2.jpg\n","tfod/workspace/images/train/Good_2.xml\n","tfod/workspace/images/train/Good_3.jpg\n","tfod/workspace/images/train/Good_3.xml\n","tfod/workspace/images/train/Good_4.jpg\n","tfod/workspace/images/train/Good_4.xml\n","tfod/workspace/images/train/Good_5.jpg\n","tfod/workspace/images/train/Good_5.xml\n","tfod/workspace/images/train/Good_6.jpg\n","tfod/workspace/images/train/Good_6.xml\n","tfod/workspace/images/train/Good_7.jpg\n","tfod/workspace/images/train/H5_5.xml\n","tfod/workspace/images/train/H5_1.jpg\n","tfod/workspace/images/train/H5_1.xml\n","tfod/workspace/images/train/H5_2.jpg\n","tfod/workspace/images/train/H5_2.xml\n","tfod/workspace/images/train/H5_3.jpg\n","tfod/workspace/images/train/H5_3.xml\n","tfod/workspace/images/train/H5_4.jpg\n","tfod/workspace/images/train/H5_4.xml\n","tfod/workspace/images/train/H5_5.jpg\n","tfod/workspace/images/train/PD_3.xml\n","tfod/workspace/images/train/PD_1.jpg\n","tfod/workspace/images/train/PD_1.xml\n","tfod/workspace/images/train/PD_2.jpg\n","tfod/workspace/images/train/PD_2.xml\n","tfod/workspace/images/train/PD_3.jpg\n","tfod/workspace/images/train/PL_3.xml\n","tfod/workspace/images/train/PL_1.jpg\n","tfod/workspace/images/train/PL_1.xml\n","tfod/workspace/images/train/PL_2.jpg\n","tfod/workspace/images/train/PL_2.xml\n","tfod/workspace/images/train/PL_3.jpg\n","tfod/workspace/images/train/PR_6.xml\n","tfod/workspace/images/train/PR_1.jpg\n","tfod/workspace/images/train/PR_1.xml\n","tfod/workspace/images/train/PR_3.jpg\n","tfod/workspace/images/train/PR_3.xml\n","tfod/workspace/images/train/PR_4.jpg\n","tfod/workspace/images/train/PR_4.xml\n","tfod/workspace/images/train/PR_5.jpg\n","tfod/workspace/images/train/PR_5.xml\n","tfod/workspace/images/train/PR_6.jpg\n","tfod/workspace/images/train/PU_4.xml\n","tfod/workspace/images/train/PU_1.jpg\n","tfod/workspace/images/train/PU_1.xml\n","tfod/workspace/images/train/PU_2.jpg\n","tfod/workspace/images/train/PU_2.xml\n","tfod/workspace/images/train/PU_3.jpg\n","tfod/workspace/images/train/PU_3.xml\n","tfod/workspace/images/train/PU_4.jpg\n","tfod/workspace/images/test/\n","tfod/workspace/images/test/Good_11.xml\n","tfod/workspace/images/test/Good_8.jpg\n","tfod/workspace/images/test/Good_8.xml\n","tfod/workspace/images/test/Good_9.jpg\n","tfod/workspace/images/test/Good_9.xml\n","tfod/workspace/images/test/Good_10.jpg\n","tfod/workspace/images/test/Good_10.xml\n","tfod/workspace/images/test/Good_11.jpg\n","tfod/workspace/images/test/H5_8.xml\n","tfod/workspace/images/test/H5_6.jpg\n","tfod/workspace/images/test/H5_6.xml\n","tfod/workspace/images/test/H5_7.jpg\n","tfod/workspace/images/test/H5_7.xml\n","tfod/workspace/images/test/H5_8.jpg\n","tfod/workspace/images/test/PD_5.xml\n","tfod/workspace/images/test/PD_4.jpg\n","tfod/workspace/images/test/PD_4.xml\n","tfod/workspace/images/test/PD_5.jpg\n","tfod/workspace/images/test/PL_5.xml\n","tfod/workspace/images/test/PL_4.jpg\n","tfod/workspace/images/test/PL_4.xml\n","tfod/workspace/images/test/PL_5.jpg\n","tfod/workspace/images/test/PR_11.xml\n","tfod/workspace/images/test/PR_7.jpg\n","tfod/workspace/images/test/PR_7.xml\n","tfod/workspace/images/test/PR_8.jpg\n","tfod/workspace/images/test/PR_8.xml\n","tfod/workspace/images/test/PR_9.jpg\n","tfod/workspace/images/test/PR_9.xml\n","tfod/workspace/images/test/PR_10.jpg\n","tfod/workspace/images/test/PR_10.xml\n","tfod/workspace/images/test/PR_11.jpg\n","tfod/workspace/images/test/PU_5.jpg\n","tfod/workspace/images/test/PU_5.xml\n","tfod/workspace/images/test/PU_6.jpg\n","tfod/workspace/images/test/PU_6.xml\n"]}],"source":["# OPTIONAL IF RUNNING ON COLAB\n","ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n","if os.path.exists(ARCHIVE_FILES):\n","  !tar -zxvf {ARCHIVE_FILES}"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":684,"status":"ok","timestamp":1650637738169,"user":{"displayName":"NNM_","userId":"18288667490642199446"},"user_tz":240},"id":"KWpb_BVUpfDD","outputId":"a7e3dbe5-fac9-4f60-c3aa-2963f28967ff"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'tfod/scripts'...\n","remote: Enumerating objects: 3, done.\u001b[K\n","remote: Counting objects: 100% (3/3), done.\u001b[K\n","remote: Compressing objects: 100% (2/2), done.\u001b[K\n","remote: Total 3 (delta 0), reused 1 (delta 0), pack-reused 0\u001b[K\n","Unpacking objects: 100% (3/3), done.\n"]}],"source":["if not os.path.exists(files['TF_RECORD_SCRIPT']):\n","    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6532,"status":"ok","timestamp":1650637771732,"user":{"displayName":"NNM_","userId":"18288667490642199446"},"user_tz":240},"id":"UPFToGZqpfDD","outputId":"be0d9a34-d318-46f5-f0b1-04bbaeb8fa92"},"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully created the TFRecord file: tfod/workspace/annotations/train.record\n","Successfully created the TFRecord file: tfod/workspace/annotations/test.record\n"]}],"source":["!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n","!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} "]},{"cell_type":"markdown","metadata":{"id":"qT4QU7pLpfDE"},"source":["# 4. Copy Model Config to Training Folder\n","# Skip, if not training, or using pipeline from exported model"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":242,"status":"ok","timestamp":1650637775061,"user":{"displayName":"NNM_","userId":"18288667490642199446"},"user_tz":240},"id":"cOjuTFbwpfDF"},"outputs":[],"source":["if os.name =='posix':\n","    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n","if os.name == 'nt':\n","    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"]},{"cell_type":"markdown","metadata":{"id":"Ga8gpNslpfDF"},"source":["# 5. Update Config For Transfer Learning\n","# Skip, if not training, or using pipeline from exported model"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":137,"status":"ok","timestamp":1650637777260,"user":{"displayName":"NNM_","userId":"18288667490642199446"},"user_tz":240},"id":"Z9hRrO_ppfDF"},"outputs":[],"source":["import tensorflow as tf\n","from object_detection.utils import config_util\n","from object_detection.protos import pipeline_pb2\n","from google.protobuf import text_format"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":116,"status":"ok","timestamp":1650637778941,"user":{"displayName":"NNM_","userId":"18288667490642199446"},"user_tz":240},"id":"c2A0mn4ipfDF"},"outputs":[],"source":["config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"uQA13-afpfDF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650637780788,"user_tz":240,"elapsed":145,"user":{"displayName":"NNM_","userId":"18288667490642199446"}},"outputId":"b1302f4f-d61f-4e3b-ba29-f5200ba49995"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'eval_config': metrics_set: \"coco_detection_metrics\"\n"," use_moving_averages: false,\n"," 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n"," shuffle: false\n"," num_epochs: 1\n"," tf_record_input_reader {\n","   input_path: \"PATH_TO_BE_CONFIGURED\"\n"," },\n"," 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n"," shuffle: false\n"," num_epochs: 1\n"," tf_record_input_reader {\n","   input_path: \"PATH_TO_BE_CONFIGURED\"\n"," }\n"," ],\n"," 'model': ssd {\n","   num_classes: 90\n","   image_resizer {\n","     fixed_shape_resizer {\n","       height: 640\n","       width: 640\n","     }\n","   }\n","   feature_extractor {\n","     type: \"ssd_mobilenet_v2_fpn_keras\"\n","     depth_multiplier: 1.0\n","     min_depth: 16\n","     conv_hyperparams {\n","       regularizer {\n","         l2_regularizer {\n","           weight: 3.9999998989515007e-05\n","         }\n","       }\n","       initializer {\n","         random_normal_initializer {\n","           mean: 0.0\n","           stddev: 0.009999999776482582\n","         }\n","       }\n","       activation: RELU_6\n","       batch_norm {\n","         decay: 0.996999979019165\n","         scale: true\n","         epsilon: 0.0010000000474974513\n","       }\n","     }\n","     use_depthwise: true\n","     override_base_feature_extractor_hyperparams: true\n","     fpn {\n","       min_level: 3\n","       max_level: 7\n","       additional_layer_depth: 128\n","     }\n","   }\n","   box_coder {\n","     faster_rcnn_box_coder {\n","       y_scale: 10.0\n","       x_scale: 10.0\n","       height_scale: 5.0\n","       width_scale: 5.0\n","     }\n","   }\n","   matcher {\n","     argmax_matcher {\n","       matched_threshold: 0.5\n","       unmatched_threshold: 0.5\n","       ignore_thresholds: false\n","       negatives_lower_than_unmatched: true\n","       force_match_for_each_row: true\n","       use_matmul_gather: true\n","     }\n","   }\n","   similarity_calculator {\n","     iou_similarity {\n","     }\n","   }\n","   box_predictor {\n","     weight_shared_convolutional_box_predictor {\n","       conv_hyperparams {\n","         regularizer {\n","           l2_regularizer {\n","             weight: 3.9999998989515007e-05\n","           }\n","         }\n","         initializer {\n","           random_normal_initializer {\n","             mean: 0.0\n","             stddev: 0.009999999776482582\n","           }\n","         }\n","         activation: RELU_6\n","         batch_norm {\n","           decay: 0.996999979019165\n","           scale: true\n","           epsilon: 0.0010000000474974513\n","         }\n","       }\n","       depth: 128\n","       num_layers_before_predictor: 4\n","       kernel_size: 3\n","       class_prediction_bias_init: -4.599999904632568\n","       share_prediction_tower: true\n","       use_depthwise: true\n","     }\n","   }\n","   anchor_generator {\n","     multiscale_anchor_generator {\n","       min_level: 3\n","       max_level: 7\n","       anchor_scale: 4.0\n","       aspect_ratios: 1.0\n","       aspect_ratios: 2.0\n","       aspect_ratios: 0.5\n","       scales_per_octave: 2\n","     }\n","   }\n","   post_processing {\n","     batch_non_max_suppression {\n","       score_threshold: 9.99999993922529e-09\n","       iou_threshold: 0.6000000238418579\n","       max_detections_per_class: 100\n","       max_total_detections: 100\n","       use_static_shapes: false\n","     }\n","     score_converter: SIGMOID\n","   }\n","   normalize_loss_by_num_matches: true\n","   loss {\n","     localization_loss {\n","       weighted_smooth_l1 {\n","       }\n","     }\n","     classification_loss {\n","       weighted_sigmoid_focal {\n","         gamma: 2.0\n","         alpha: 0.25\n","       }\n","     }\n","     classification_weight: 1.0\n","     localization_weight: 1.0\n","   }\n","   encode_background_as_zeros: true\n","   normalize_loc_loss_by_codesize: true\n","   inplace_batchnorm_update: true\n","   freeze_batchnorm: false\n"," },\n"," 'train_config': batch_size: 128\n"," data_augmentation_options {\n","   random_horizontal_flip {\n","   }\n"," }\n"," data_augmentation_options {\n","   random_crop_image {\n","     min_object_covered: 0.0\n","     min_aspect_ratio: 0.75\n","     max_aspect_ratio: 3.0\n","     min_area: 0.75\n","     max_area: 1.0\n","     overlap_thresh: 0.0\n","   }\n"," }\n"," sync_replicas: true\n"," optimizer {\n","   momentum_optimizer {\n","     learning_rate {\n","       cosine_decay_learning_rate {\n","         learning_rate_base: 0.07999999821186066\n","         total_steps: 50000\n","         warmup_learning_rate: 0.026666000485420227\n","         warmup_steps: 1000\n","       }\n","     }\n","     momentum_optimizer_value: 0.8999999761581421\n","   }\n","   use_moving_average: false\n"," }\n"," fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n"," num_steps: 50000\n"," startup_delay_steps: 0.0\n"," replicas_to_aggregate: 8\n"," max_number_of_boxes: 100\n"," unpad_groundtruth_tensors: false\n"," fine_tune_checkpoint_type: \"classification\"\n"," fine_tune_checkpoint_version: V2,\n"," 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n"," tf_record_input_reader {\n","   input_path: \"PATH_TO_BE_CONFIGURED\"\n"," }}"]},"metadata":{},"execution_count":23}],"source":["config"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":130,"status":"ok","timestamp":1650637785200,"user":{"displayName":"NNM_","userId":"18288667490642199446"},"user_tz":240},"id":"9vK5lotDpfDF"},"outputs":[],"source":["pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n","with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n","    proto_str = f.read()                                                                                                                                                                                                                                          \n","    text_format.Merge(proto_str, pipeline_config)  "]},{"cell_type":"code","source":["pipeline_config"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a2dDMzyFzwoY","executionInfo":{"status":"ok","timestamp":1650571684074,"user_tz":240,"elapsed":6,"user":{"displayName":"NNM_","userId":"18288667490642199446"}},"outputId":"e649a123-1280-4c8b-9eac-e4dd02957482"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["model {\n","  ssd {\n","    num_classes: 6\n","    image_resizer {\n","      fixed_shape_resizer {\n","        height: 640\n","        width: 640\n","      }\n","    }\n","    feature_extractor {\n","      type: \"ssd_mobilenet_v2_fpn_keras\"\n","      depth_multiplier: 1.0\n","      min_depth: 16\n","      conv_hyperparams {\n","        regularizer {\n","          l2_regularizer {\n","            weight: 3.9999998989515007e-05\n","          }\n","        }\n","        initializer {\n","          random_normal_initializer {\n","            mean: 0.0\n","            stddev: 0.009999999776482582\n","          }\n","        }\n","        activation: RELU_6\n","        batch_norm {\n","          decay: 0.996999979019165\n","          scale: true\n","          epsilon: 0.0010000000474974513\n","        }\n","      }\n","      use_depthwise: true\n","      override_base_feature_extractor_hyperparams: true\n","      fpn {\n","        min_level: 3\n","        max_level: 7\n","        additional_layer_depth: 64\n","      }\n","    }\n","    box_coder {\n","      faster_rcnn_box_coder {\n","        y_scale: 10.0\n","        x_scale: 10.0\n","        height_scale: 5.0\n","        width_scale: 5.0\n","      }\n","    }\n","    matcher {\n","      argmax_matcher {\n","        matched_threshold: 0.5\n","        unmatched_threshold: 0.5\n","        ignore_thresholds: false\n","        negatives_lower_than_unmatched: true\n","        force_match_for_each_row: true\n","        use_matmul_gather: true\n","      }\n","    }\n","    similarity_calculator {\n","      iou_similarity {\n","      }\n","    }\n","    box_predictor {\n","      weight_shared_convolutional_box_predictor {\n","        conv_hyperparams {\n","          regularizer {\n","            l2_regularizer {\n","              weight: 3.9999998989515007e-05\n","            }\n","          }\n","          initializer {\n","            random_normal_initializer {\n","              mean: 0.0\n","              stddev: 0.009999999776482582\n","            }\n","          }\n","          activation: RELU_6\n","          batch_norm {\n","            decay: 0.996999979019165\n","            scale: true\n","            epsilon: 0.0010000000474974513\n","          }\n","        }\n","        depth: 64\n","        num_layers_before_predictor: 4\n","        kernel_size: 3\n","        class_prediction_bias_init: -4.599999904632568\n","        share_prediction_tower: true\n","        use_depthwise: true\n","      }\n","    }\n","    anchor_generator {\n","      multiscale_anchor_generator {\n","        min_level: 3\n","        max_level: 7\n","        anchor_scale: 4.0\n","        aspect_ratios: 1.0\n","        aspect_ratios: 2.0\n","        aspect_ratios: 0.5\n","        scales_per_octave: 2\n","      }\n","    }\n","    post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 9.99999993922529e-09\n","        iou_threshold: 0.6000000238418579\n","        max_detections_per_class: 100\n","        max_total_detections: 100\n","        use_static_shapes: false\n","      }\n","      score_converter: SIGMOID\n","    }\n","    normalize_loss_by_num_matches: true\n","    loss {\n","      localization_loss {\n","        weighted_smooth_l1 {\n","        }\n","      }\n","      classification_loss {\n","        weighted_sigmoid_focal {\n","          gamma: 2.0\n","          alpha: 0.25\n","        }\n","      }\n","      classification_weight: 1.0\n","      localization_weight: 1.0\n","    }\n","    encode_background_as_zeros: true\n","    normalize_loc_loss_by_codesize: true\n","    inplace_batchnorm_update: true\n","    freeze_batchnorm: false\n","  }\n","}\n","train_config {\n","  batch_size: 16\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","  }\n","  data_augmentation_options {\n","    random_crop_image {\n","      min_object_covered: 0.0\n","      min_aspect_ratio: 0.75\n","      max_aspect_ratio: 3.0\n","      min_area: 0.75\n","      max_area: 1.0\n","      overlap_thresh: 0.0\n","    }\n","  }\n","  sync_replicas: true\n","  optimizer {\n","    momentum_optimizer {\n","      learning_rate {\n","        cosine_decay_learning_rate {\n","          learning_rate_base: 0.07999999821186066\n","          total_steps: 50000\n","          warmup_learning_rate: 0.026666000485420227\n","          warmup_steps: 1000\n","        }\n","      }\n","      momentum_optimizer_value: 0.8999999761581421\n","    }\n","    use_moving_average: false\n","  }\n","  fine_tune_checkpoint: \"tfod/workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0\"\n","  num_steps: 50000\n","  startup_delay_steps: 0.0\n","  replicas_to_aggregate: 8\n","  max_number_of_boxes: 100\n","  unpad_groundtruth_tensors: false\n","  fine_tune_checkpoint_type: \"detection\"\n","  fine_tune_checkpoint_version: V2\n","}\n","train_input_reader {\n","  label_map_path: \"tfod/workspace/annotations/label_map.pbtxt\"\n","  tf_record_input_reader {\n","    input_path: \"tfod/workspace/annotations/train.record\"\n","  }\n","}\n","eval_config {\n","  metrics_set: \"coco_detection_metrics\"\n","  use_moving_averages: false\n","}\n","eval_input_reader {\n","  label_map_path: \"tfod/workspace/annotations/label_map.pbtxt\"\n","  shuffle: false\n","  num_epochs: 1\n","  tf_record_input_reader {\n","    input_path: \"tfod/workspace/annotations/test.record\"\n","  }\n","}"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":127,"status":"ok","timestamp":1650637847057,"user":{"displayName":"NNM_","userId":"18288667490642199446"},"user_tz":240},"id":"rP43Ph0JpfDG"},"outputs":[],"source":["pipeline_config.model.ssd.num_classes = len(labels)\n","pipeline_config.model.ssd.feature_extractor.fpn.additional_layer_depth = 128\n","pipeline_config.model.ssd.box_predictor.weight_shared_convolutional_box_predictor.depth = 32\n","\n","pipeline_config.model.ssd.post_processing.batch_non_max_suppression.iou_threshold = 0.6\n","pipeline_config.train_config.batch_size = 16\n","pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n","pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n","pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n","pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n","pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n","pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":135,"status":"ok","timestamp":1650637849179,"user":{"displayName":"NNM_","userId":"18288667490642199446"},"user_tz":240},"id":"oJvfgwWqpfDG"},"outputs":[],"source":["config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n","with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n","    f.write(config_text)   "]},{"cell_type":"code","source":["pipeline_config"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xl8wJXpS0p9-","executionInfo":{"status":"ok","timestamp":1650637851619,"user_tz":240,"elapsed":138,"user":{"displayName":"NNM_","userId":"18288667490642199446"}},"outputId":"d22fe951-b632-40b6-aeae-5feddaa613ae"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["model {\n","  ssd {\n","    num_classes: 6\n","    image_resizer {\n","      fixed_shape_resizer {\n","        height: 640\n","        width: 640\n","      }\n","    }\n","    feature_extractor {\n","      type: \"ssd_mobilenet_v2_fpn_keras\"\n","      depth_multiplier: 1.0\n","      min_depth: 16\n","      conv_hyperparams {\n","        regularizer {\n","          l2_regularizer {\n","            weight: 3.9999998989515007e-05\n","          }\n","        }\n","        initializer {\n","          random_normal_initializer {\n","            mean: 0.0\n","            stddev: 0.009999999776482582\n","          }\n","        }\n","        activation: RELU_6\n","        batch_norm {\n","          decay: 0.996999979019165\n","          scale: true\n","          epsilon: 0.0010000000474974513\n","        }\n","      }\n","      use_depthwise: true\n","      override_base_feature_extractor_hyperparams: true\n","      fpn {\n","        min_level: 3\n","        max_level: 7\n","        additional_layer_depth: 128\n","      }\n","    }\n","    box_coder {\n","      faster_rcnn_box_coder {\n","        y_scale: 10.0\n","        x_scale: 10.0\n","        height_scale: 5.0\n","        width_scale: 5.0\n","      }\n","    }\n","    matcher {\n","      argmax_matcher {\n","        matched_threshold: 0.5\n","        unmatched_threshold: 0.5\n","        ignore_thresholds: false\n","        negatives_lower_than_unmatched: true\n","        force_match_for_each_row: true\n","        use_matmul_gather: true\n","      }\n","    }\n","    similarity_calculator {\n","      iou_similarity {\n","      }\n","    }\n","    box_predictor {\n","      weight_shared_convolutional_box_predictor {\n","        conv_hyperparams {\n","          regularizer {\n","            l2_regularizer {\n","              weight: 3.9999998989515007e-05\n","            }\n","          }\n","          initializer {\n","            random_normal_initializer {\n","              mean: 0.0\n","              stddev: 0.009999999776482582\n","            }\n","          }\n","          activation: RELU_6\n","          batch_norm {\n","            decay: 0.996999979019165\n","            scale: true\n","            epsilon: 0.0010000000474974513\n","          }\n","        }\n","        depth: 32\n","        num_layers_before_predictor: 4\n","        kernel_size: 3\n","        class_prediction_bias_init: -4.599999904632568\n","        share_prediction_tower: true\n","        use_depthwise: true\n","      }\n","    }\n","    anchor_generator {\n","      multiscale_anchor_generator {\n","        min_level: 3\n","        max_level: 7\n","        anchor_scale: 4.0\n","        aspect_ratios: 1.0\n","        aspect_ratios: 2.0\n","        aspect_ratios: 0.5\n","        scales_per_octave: 2\n","      }\n","    }\n","    post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 9.99999993922529e-09\n","        iou_threshold: 0.6000000238418579\n","        max_detections_per_class: 100\n","        max_total_detections: 100\n","        use_static_shapes: false\n","      }\n","      score_converter: SIGMOID\n","    }\n","    normalize_loss_by_num_matches: true\n","    loss {\n","      localization_loss {\n","        weighted_smooth_l1 {\n","        }\n","      }\n","      classification_loss {\n","        weighted_sigmoid_focal {\n","          gamma: 2.0\n","          alpha: 0.25\n","        }\n","      }\n","      classification_weight: 1.0\n","      localization_weight: 1.0\n","    }\n","    encode_background_as_zeros: true\n","    normalize_loc_loss_by_codesize: true\n","    inplace_batchnorm_update: true\n","    freeze_batchnorm: false\n","  }\n","}\n","train_config {\n","  batch_size: 16\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","  }\n","  data_augmentation_options {\n","    random_crop_image {\n","      min_object_covered: 0.0\n","      min_aspect_ratio: 0.75\n","      max_aspect_ratio: 3.0\n","      min_area: 0.75\n","      max_area: 1.0\n","      overlap_thresh: 0.0\n","    }\n","  }\n","  sync_replicas: true\n","  optimizer {\n","    momentum_optimizer {\n","      learning_rate {\n","        cosine_decay_learning_rate {\n","          learning_rate_base: 0.07999999821186066\n","          total_steps: 50000\n","          warmup_learning_rate: 0.026666000485420227\n","          warmup_steps: 1000\n","        }\n","      }\n","      momentum_optimizer_value: 0.8999999761581421\n","    }\n","    use_moving_average: false\n","  }\n","  fine_tune_checkpoint: \"tfod/workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0\"\n","  num_steps: 50000\n","  startup_delay_steps: 0.0\n","  replicas_to_aggregate: 8\n","  max_number_of_boxes: 100\n","  unpad_groundtruth_tensors: false\n","  fine_tune_checkpoint_type: \"detection\"\n","  fine_tune_checkpoint_version: V2\n","}\n","train_input_reader {\n","  label_map_path: \"tfod/workspace/annotations/label_map.pbtxt\"\n","  tf_record_input_reader {\n","    input_path: \"tfod/workspace/annotations/train.record\"\n","  }\n","}\n","eval_config {\n","  metrics_set: \"coco_detection_metrics\"\n","  use_moving_averages: false\n","}\n","eval_input_reader {\n","  label_map_path: \"tfod/workspace/annotations/label_map.pbtxt\"\n","  shuffle: false\n","  num_epochs: 1\n","  tf_record_input_reader {\n","    input_path: \"tfod/workspace/annotations/test.record\"\n","  }\n","}"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"Zr3ON7xMpfDG"},"source":["# 6. Train the model\n","# Skip, if not training"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":120,"status":"ok","timestamp":1650637865073,"user":{"displayName":"NNM_","userId":"18288667490642199446"},"user_tz":240},"id":"B-Y2UQmQpfDG"},"outputs":[],"source":["TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":111,"status":"ok","timestamp":1650637865933,"user":{"displayName":"NNM_","userId":"18288667490642199446"},"user_tz":240},"id":"jMP2XDfQpfDH"},"outputs":[],"source":["command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=4000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":147,"status":"ok","timestamp":1650637866833,"user":{"displayName":"NNM_","userId":"18288667490642199446"},"user_tz":240},"id":"A4OXXi-ApfDH","outputId":"d15fa1b0-adf9-4a95-967d-dee07433f63f"},"outputs":[{"output_type":"stream","name":"stdout","text":["python tfod/models/research/object_detection/model_main_tf2.py --model_dir=tfod/workspace/models/my_ssd_mobilnet_v2 --pipeline_config_path=tfod/workspace/models/my_ssd_mobilnet_v2/pipeline.config --num_train_steps=4000\n"]}],"source":["print(command)"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5524,"status":"ok","timestamp":1650637873723,"user":{"displayName":"NNM_","userId":"18288667490642199446"},"user_tz":240},"id":"xDMnWJH3nJWL","outputId":"5bd80545-3659-479d-f90e-0da2c74a440e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting opencv-python-headless==4.1.2.30\n","  Downloading opencv_python_headless-4.1.2.30-cp37-cp37m-manylinux1_x86_64.whl (21.8 MB)\n","\u001b[K     |████████████████████████████████| 21.8 MB 1.4 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.1.2.30) (1.21.6)\n","Installing collected packages: opencv-python-headless\n","  Attempting uninstall: opencv-python-headless\n","    Found existing installation: opencv-python-headless 4.5.5.64\n","    Uninstalling opencv-python-headless-4.5.5.64:\n","      Successfully uninstalled opencv-python-headless-4.5.5.64\n","Successfully installed opencv-python-headless-4.1.2.30\n"]}],"source":["!pip install opencv-python-headless==4.1.2.30"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5741866,"status":"ok","timestamp":1650643620097,"user":{"displayName":"NNM_","userId":"18288667490642199446"},"user_tz":240},"id":"i3ZsJR-qpfDH","outputId":"80f7501d-bb30-4d15-8a77-13c40d3cd96e"},"outputs":[{"output_type":"stream","name":"stdout","text":["2022-04-22 14:31:23.919661: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","I0422 14:31:23.925995 140003774904192 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","INFO:tensorflow:Maybe overwriting train_steps: 4000\n","I0422 14:31:23.930207 140003774904192 config_util.py:552] Maybe overwriting train_steps: 4000\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0422 14:31:23.930379 140003774904192 config_util.py:552] Maybe overwriting use_bfloat16: False\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","W0422 14:31:24.084637 140003774904192 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","INFO:tensorflow:Reading unweighted datasets: ['tfod/workspace/annotations/train.record']\n","I0422 14:31:24.107383 140003774904192 dataset_builder.py:162] Reading unweighted datasets: ['tfod/workspace/annotations/train.record']\n","INFO:tensorflow:Reading record datasets for input file: ['tfod/workspace/annotations/train.record']\n","I0422 14:31:24.107659 140003774904192 dataset_builder.py:79] Reading record datasets for input file: ['tfod/workspace/annotations/train.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0422 14:31:24.107775 140003774904192 dataset_builder.py:80] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0422 14:31:24.107865 140003774904192 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","W0422 14:31:24.113639 140003774904192 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0422 14:31:24.142438 140003774904192 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W0422 14:31:31.710754 140003774904192 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","W0422 14:31:35.013847 140003774904192 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0422 14:31:36.799722 140003774904192 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","/usr/local/lib/python3.7/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0422 14:32:20.573222 140003774904192 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0422 14:32:20.574517 140003774904192 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0422 14:32:20.576702 140003774904192 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0422 14:32:20.577651 140003774904192 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0422 14:32:20.579834 140003774904192 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0422 14:32:20.580771 140003774904192 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0422 14:32:20.582919 140003774904192 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0422 14:32:20.583858 140003774904192 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0422 14:32:20.585975 140003774904192 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0422 14:32:20.586917 140003774904192 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","W0422 14:32:21.253910 139998613141248 deprecation.py:547] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","INFO:tensorflow:Step 100 per-step time 1.918s\n","I0422 14:35:32.925102 140003774904192 model_lib_v2.py:707] Step 100 per-step time 1.918s\n","INFO:tensorflow:{'Loss/classification_loss': 0.25450766,\n"," 'Loss/localization_loss': 0.12955756,\n"," 'Loss/regularization_loss': 0.15143757,\n"," 'Loss/total_loss': 0.5355028,\n"," 'learning_rate': 0.0319994}\n","I0422 14:35:32.925562 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.25450766,\n"," 'Loss/localization_loss': 0.12955756,\n"," 'Loss/regularization_loss': 0.15143757,\n"," 'Loss/total_loss': 0.5355028,\n"," 'learning_rate': 0.0319994}\n","INFO:tensorflow:Step 200 per-step time 1.389s\n","I0422 14:37:51.574871 140003774904192 model_lib_v2.py:707] Step 200 per-step time 1.389s\n","INFO:tensorflow:{'Loss/classification_loss': 0.17912968,\n"," 'Loss/localization_loss': 0.09860171,\n"," 'Loss/regularization_loss': 0.15119459,\n"," 'Loss/total_loss': 0.428926,\n"," 'learning_rate': 0.0373328}\n","I0422 14:37:51.575234 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.17912968,\n"," 'Loss/localization_loss': 0.09860171,\n"," 'Loss/regularization_loss': 0.15119459,\n"," 'Loss/total_loss': 0.428926,\n"," 'learning_rate': 0.0373328}\n","INFO:tensorflow:Step 300 per-step time 1.403s\n","I0422 14:40:11.900310 140003774904192 model_lib_v2.py:707] Step 300 per-step time 1.403s\n","INFO:tensorflow:{'Loss/classification_loss': 0.12188175,\n"," 'Loss/localization_loss': 0.05990485,\n"," 'Loss/regularization_loss': 0.15086071,\n"," 'Loss/total_loss': 0.33264732,\n"," 'learning_rate': 0.0426662}\n","I0422 14:40:11.900659 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.12188175,\n"," 'Loss/localization_loss': 0.05990485,\n"," 'Loss/regularization_loss': 0.15086071,\n"," 'Loss/total_loss': 0.33264732,\n"," 'learning_rate': 0.0426662}\n","INFO:tensorflow:Step 400 per-step time 1.406s\n","I0422 14:42:32.532213 140003774904192 model_lib_v2.py:707] Step 400 per-step time 1.406s\n","INFO:tensorflow:{'Loss/classification_loss': 0.096019395,\n"," 'Loss/localization_loss': 0.042395186,\n"," 'Loss/regularization_loss': 0.1504758,\n"," 'Loss/total_loss': 0.28889036,\n"," 'learning_rate': 0.047999598}\n","I0422 14:42:32.532567 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.096019395,\n"," 'Loss/localization_loss': 0.042395186,\n"," 'Loss/regularization_loss': 0.1504758,\n"," 'Loss/total_loss': 0.28889036,\n"," 'learning_rate': 0.047999598}\n","INFO:tensorflow:Step 500 per-step time 1.403s\n","I0422 14:44:52.811873 140003774904192 model_lib_v2.py:707] Step 500 per-step time 1.403s\n","INFO:tensorflow:{'Loss/classification_loss': 0.099022195,\n"," 'Loss/localization_loss': 0.07138763,\n"," 'Loss/regularization_loss': 0.15006067,\n"," 'Loss/total_loss': 0.3204705,\n"," 'learning_rate': 0.053333}\n","I0422 14:44:52.812209 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.099022195,\n"," 'Loss/localization_loss': 0.07138763,\n"," 'Loss/regularization_loss': 0.15006067,\n"," 'Loss/total_loss': 0.3204705,\n"," 'learning_rate': 0.053333}\n","INFO:tensorflow:Step 600 per-step time 1.409s\n","I0422 14:47:13.694769 140003774904192 model_lib_v2.py:707] Step 600 per-step time 1.409s\n","INFO:tensorflow:{'Loss/classification_loss': 0.10505727,\n"," 'Loss/localization_loss': 0.03465316,\n"," 'Loss/regularization_loss': 0.14957757,\n"," 'Loss/total_loss': 0.28928798,\n"," 'learning_rate': 0.0586664}\n","I0422 14:47:13.695106 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.10505727,\n"," 'Loss/localization_loss': 0.03465316,\n"," 'Loss/regularization_loss': 0.14957757,\n"," 'Loss/total_loss': 0.28928798,\n"," 'learning_rate': 0.0586664}\n","INFO:tensorflow:Step 700 per-step time 1.406s\n","I0422 14:49:34.247349 140003774904192 model_lib_v2.py:707] Step 700 per-step time 1.406s\n","INFO:tensorflow:{'Loss/classification_loss': 0.09660195,\n"," 'Loss/localization_loss': 0.032809574,\n"," 'Loss/regularization_loss': 0.14901312,\n"," 'Loss/total_loss': 0.27842462,\n"," 'learning_rate': 0.0639998}\n","I0422 14:49:34.247721 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.09660195,\n"," 'Loss/localization_loss': 0.032809574,\n"," 'Loss/regularization_loss': 0.14901312,\n"," 'Loss/total_loss': 0.27842462,\n"," 'learning_rate': 0.0639998}\n","INFO:tensorflow:Step 800 per-step time 1.408s\n","I0422 14:51:55.021515 140003774904192 model_lib_v2.py:707] Step 800 per-step time 1.408s\n","INFO:tensorflow:{'Loss/classification_loss': 0.08420595,\n"," 'Loss/localization_loss': 0.02739169,\n"," 'Loss/regularization_loss': 0.14843556,\n"," 'Loss/total_loss': 0.26003322,\n"," 'learning_rate': 0.069333196}\n","I0422 14:51:55.021883 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.08420595,\n"," 'Loss/localization_loss': 0.02739169,\n"," 'Loss/regularization_loss': 0.14843556,\n"," 'Loss/total_loss': 0.26003322,\n"," 'learning_rate': 0.069333196}\n","INFO:tensorflow:Step 900 per-step time 1.392s\n","I0422 14:54:14.228314 140003774904192 model_lib_v2.py:707] Step 900 per-step time 1.392s\n","INFO:tensorflow:{'Loss/classification_loss': 0.08637708,\n"," 'Loss/localization_loss': 0.042402808,\n"," 'Loss/regularization_loss': 0.14779465,\n"," 'Loss/total_loss': 0.27657455,\n"," 'learning_rate': 0.074666604}\n","I0422 14:54:14.228683 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.08637708,\n"," 'Loss/localization_loss': 0.042402808,\n"," 'Loss/regularization_loss': 0.14779465,\n"," 'Loss/total_loss': 0.27657455,\n"," 'learning_rate': 0.074666604}\n","INFO:tensorflow:Step 1000 per-step time 1.402s\n","I0422 14:56:34.468071 140003774904192 model_lib_v2.py:707] Step 1000 per-step time 1.402s\n","INFO:tensorflow:{'Loss/classification_loss': 0.098114684,\n"," 'Loss/localization_loss': 0.038819686,\n"," 'Loss/regularization_loss': 0.14709651,\n"," 'Loss/total_loss': 0.28403088,\n"," 'learning_rate': 0.08}\n","I0422 14:56:34.468475 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.098114684,\n"," 'Loss/localization_loss': 0.038819686,\n"," 'Loss/regularization_loss': 0.14709651,\n"," 'Loss/total_loss': 0.28403088,\n"," 'learning_rate': 0.08}\n","INFO:tensorflow:Step 1100 per-step time 1.408s\n","I0422 14:58:55.304929 140003774904192 model_lib_v2.py:707] Step 1100 per-step time 1.408s\n","INFO:tensorflow:{'Loss/classification_loss': 0.0920317,\n"," 'Loss/localization_loss': 0.04260539,\n"," 'Loss/regularization_loss': 0.14635931,\n"," 'Loss/total_loss': 0.28099638,\n"," 'learning_rate': 0.07999918}\n","I0422 14:58:55.305295 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.0920317,\n"," 'Loss/localization_loss': 0.04260539,\n"," 'Loss/regularization_loss': 0.14635931,\n"," 'Loss/total_loss': 0.28099638,\n"," 'learning_rate': 0.07999918}\n","INFO:tensorflow:Step 1200 per-step time 1.408s\n","I0422 15:01:16.127424 140003774904192 model_lib_v2.py:707] Step 1200 per-step time 1.408s\n","INFO:tensorflow:{'Loss/classification_loss': 0.078439415,\n"," 'Loss/localization_loss': 0.039497882,\n"," 'Loss/regularization_loss': 0.14571533,\n"," 'Loss/total_loss': 0.26365262,\n"," 'learning_rate': 0.079996705}\n","I0422 15:01:16.127849 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.078439415,\n"," 'Loss/localization_loss': 0.039497882,\n"," 'Loss/regularization_loss': 0.14571533,\n"," 'Loss/total_loss': 0.26365262,\n"," 'learning_rate': 0.079996705}\n","INFO:tensorflow:Step 1300 per-step time 1.410s\n","I0422 15:03:37.111817 140003774904192 model_lib_v2.py:707] Step 1300 per-step time 1.410s\n","INFO:tensorflow:{'Loss/classification_loss': 0.080508925,\n"," 'Loss/localization_loss': 0.027924009,\n"," 'Loss/regularization_loss': 0.14496092,\n"," 'Loss/total_loss': 0.25339386,\n"," 'learning_rate': 0.0799926}\n","I0422 15:03:37.112162 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.080508925,\n"," 'Loss/localization_loss': 0.027924009,\n"," 'Loss/regularization_loss': 0.14496092,\n"," 'Loss/total_loss': 0.25339386,\n"," 'learning_rate': 0.0799926}\n","INFO:tensorflow:Step 1400 per-step time 1.408s\n","I0422 15:05:57.915610 140003774904192 model_lib_v2.py:707] Step 1400 per-step time 1.408s\n","INFO:tensorflow:{'Loss/classification_loss': 0.072482474,\n"," 'Loss/localization_loss': 0.031056905,\n"," 'Loss/regularization_loss': 0.14419402,\n"," 'Loss/total_loss': 0.2477334,\n"," 'learning_rate': 0.07998685}\n","I0422 15:05:57.915966 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.072482474,\n"," 'Loss/localization_loss': 0.031056905,\n"," 'Loss/regularization_loss': 0.14419402,\n"," 'Loss/total_loss': 0.2477334,\n"," 'learning_rate': 0.07998685}\n","INFO:tensorflow:Step 1500 per-step time 1.405s\n","I0422 15:08:18.376023 140003774904192 model_lib_v2.py:707] Step 1500 per-step time 1.405s\n","INFO:tensorflow:{'Loss/classification_loss': 0.06516278,\n"," 'Loss/localization_loss': 0.027778972,\n"," 'Loss/regularization_loss': 0.143412,\n"," 'Loss/total_loss': 0.23635374,\n"," 'learning_rate': 0.07997945}\n","I0422 15:08:18.376391 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.06516278,\n"," 'Loss/localization_loss': 0.027778972,\n"," 'Loss/regularization_loss': 0.143412,\n"," 'Loss/total_loss': 0.23635374,\n"," 'learning_rate': 0.07997945}\n","INFO:tensorflow:Step 1600 per-step time 1.409s\n","I0422 15:10:39.231291 140003774904192 model_lib_v2.py:707] Step 1600 per-step time 1.409s\n","INFO:tensorflow:{'Loss/classification_loss': 0.05420611,\n"," 'Loss/localization_loss': 0.017411035,\n"," 'Loss/regularization_loss': 0.14264958,\n"," 'Loss/total_loss': 0.21426672,\n"," 'learning_rate': 0.079970405}\n","I0422 15:10:39.231632 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.05420611,\n"," 'Loss/localization_loss': 0.017411035,\n"," 'Loss/regularization_loss': 0.14264958,\n"," 'Loss/total_loss': 0.21426672,\n"," 'learning_rate': 0.079970405}\n","INFO:tensorflow:Step 1700 per-step time 1.408s\n","I0422 15:13:00.058265 140003774904192 model_lib_v2.py:707] Step 1700 per-step time 1.408s\n","INFO:tensorflow:{'Loss/classification_loss': 0.06257899,\n"," 'Loss/localization_loss': 0.017252045,\n"," 'Loss/regularization_loss': 0.141881,\n"," 'Loss/total_loss': 0.22171204,\n"," 'learning_rate': 0.07995972}\n","I0422 15:13:00.058612 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.06257899,\n"," 'Loss/localization_loss': 0.017252045,\n"," 'Loss/regularization_loss': 0.141881,\n"," 'Loss/total_loss': 0.22171204,\n"," 'learning_rate': 0.07995972}\n","INFO:tensorflow:Step 1800 per-step time 1.412s\n","I0422 15:15:21.258894 140003774904192 model_lib_v2.py:707] Step 1800 per-step time 1.412s\n","INFO:tensorflow:{'Loss/classification_loss': 0.05727007,\n"," 'Loss/localization_loss': 0.018501436,\n"," 'Loss/regularization_loss': 0.14112754,\n"," 'Loss/total_loss': 0.21689904,\n"," 'learning_rate': 0.0799474}\n","I0422 15:15:21.259253 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.05727007,\n"," 'Loss/localization_loss': 0.018501436,\n"," 'Loss/regularization_loss': 0.14112754,\n"," 'Loss/total_loss': 0.21689904,\n"," 'learning_rate': 0.0799474}\n","INFO:tensorflow:Step 1900 per-step time 1.409s\n","I0422 15:17:42.151899 140003774904192 model_lib_v2.py:707] Step 1900 per-step time 1.409s\n","INFO:tensorflow:{'Loss/classification_loss': 0.08489676,\n"," 'Loss/localization_loss': 0.015626868,\n"," 'Loss/regularization_loss': 0.1403825,\n"," 'Loss/total_loss': 0.24090612,\n"," 'learning_rate': 0.07993342}\n","I0422 15:17:42.152238 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.08489676,\n"," 'Loss/localization_loss': 0.015626868,\n"," 'Loss/regularization_loss': 0.1403825,\n"," 'Loss/total_loss': 0.24090612,\n"," 'learning_rate': 0.07993342}\n","INFO:tensorflow:Step 2000 per-step time 1.402s\n","I0422 15:20:02.353873 140003774904192 model_lib_v2.py:707] Step 2000 per-step time 1.402s\n","INFO:tensorflow:{'Loss/classification_loss': 0.053222008,\n"," 'Loss/localization_loss': 0.0220523,\n"," 'Loss/regularization_loss': 0.139621,\n"," 'Loss/total_loss': 0.21489531,\n"," 'learning_rate': 0.07991781}\n","I0422 15:20:02.354258 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.053222008,\n"," 'Loss/localization_loss': 0.0220523,\n"," 'Loss/regularization_loss': 0.139621,\n"," 'Loss/total_loss': 0.21489531,\n"," 'learning_rate': 0.07991781}\n","INFO:tensorflow:Step 2100 per-step time 1.402s\n","I0422 15:22:22.526923 140003774904192 model_lib_v2.py:707] Step 2100 per-step time 1.402s\n","INFO:tensorflow:{'Loss/classification_loss': 0.048250042,\n"," 'Loss/localization_loss': 0.021163542,\n"," 'Loss/regularization_loss': 0.13886958,\n"," 'Loss/total_loss': 0.20828317,\n"," 'learning_rate': 0.07990056}\n","I0422 15:22:22.527351 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.048250042,\n"," 'Loss/localization_loss': 0.021163542,\n"," 'Loss/regularization_loss': 0.13886958,\n"," 'Loss/total_loss': 0.20828317,\n"," 'learning_rate': 0.07990056}\n","INFO:tensorflow:Step 2200 per-step time 1.407s\n","I0422 15:24:43.232373 140003774904192 model_lib_v2.py:707] Step 2200 per-step time 1.407s\n","INFO:tensorflow:{'Loss/classification_loss': 0.03874856,\n"," 'Loss/localization_loss': 0.009471126,\n"," 'Loss/regularization_loss': 0.13809395,\n"," 'Loss/total_loss': 0.18631363,\n"," 'learning_rate': 0.07988167}\n","I0422 15:24:43.232758 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.03874856,\n"," 'Loss/localization_loss': 0.009471126,\n"," 'Loss/regularization_loss': 0.13809395,\n"," 'Loss/total_loss': 0.18631363,\n"," 'learning_rate': 0.07988167}\n","INFO:tensorflow:Step 2300 per-step time 1.403s\n","I0422 15:27:03.526177 140003774904192 model_lib_v2.py:707] Step 2300 per-step time 1.403s\n","INFO:tensorflow:{'Loss/classification_loss': 0.05686227,\n"," 'Loss/localization_loss': 0.023933861,\n"," 'Loss/regularization_loss': 0.13735604,\n"," 'Loss/total_loss': 0.21815217,\n"," 'learning_rate': 0.07986114}\n","I0422 15:27:03.526575 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.05686227,\n"," 'Loss/localization_loss': 0.023933861,\n"," 'Loss/regularization_loss': 0.13735604,\n"," 'Loss/total_loss': 0.21815217,\n"," 'learning_rate': 0.07986114}\n","INFO:tensorflow:Step 2400 per-step time 1.403s\n","I0422 15:29:23.798065 140003774904192 model_lib_v2.py:707] Step 2400 per-step time 1.403s\n","INFO:tensorflow:{'Loss/classification_loss': 0.05536642,\n"," 'Loss/localization_loss': 0.011469849,\n"," 'Loss/regularization_loss': 0.13659792,\n"," 'Loss/total_loss': 0.20343418,\n"," 'learning_rate': 0.07983897}\n","I0422 15:29:23.798426 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.05536642,\n"," 'Loss/localization_loss': 0.011469849,\n"," 'Loss/regularization_loss': 0.13659792,\n"," 'Loss/total_loss': 0.20343418,\n"," 'learning_rate': 0.07983897}\n","INFO:tensorflow:Step 2500 per-step time 1.408s\n","I0422 15:31:44.554198 140003774904192 model_lib_v2.py:707] Step 2500 per-step time 1.408s\n","INFO:tensorflow:{'Loss/classification_loss': 0.04612274,\n"," 'Loss/localization_loss': 0.009620773,\n"," 'Loss/regularization_loss': 0.1358635,\n"," 'Loss/total_loss': 0.19160701,\n"," 'learning_rate': 0.079815164}\n","I0422 15:31:44.554566 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.04612274,\n"," 'Loss/localization_loss': 0.009620773,\n"," 'Loss/regularization_loss': 0.1358635,\n"," 'Loss/total_loss': 0.19160701,\n"," 'learning_rate': 0.079815164}\n","INFO:tensorflow:Step 2600 per-step time 1.403s\n","I0422 15:34:04.852138 140003774904192 model_lib_v2.py:707] Step 2600 per-step time 1.403s\n","INFO:tensorflow:{'Loss/classification_loss': 0.070848644,\n"," 'Loss/localization_loss': 0.012298881,\n"," 'Loss/regularization_loss': 0.13510479,\n"," 'Loss/total_loss': 0.21825232,\n"," 'learning_rate': 0.07978972}\n","I0422 15:34:04.852456 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.070848644,\n"," 'Loss/localization_loss': 0.012298881,\n"," 'Loss/regularization_loss': 0.13510479,\n"," 'Loss/total_loss': 0.21825232,\n"," 'learning_rate': 0.07978972}\n","INFO:tensorflow:Step 2700 per-step time 1.405s\n","I0422 15:36:25.355307 140003774904192 model_lib_v2.py:707] Step 2700 per-step time 1.405s\n","INFO:tensorflow:{'Loss/classification_loss': 0.062320136,\n"," 'Loss/localization_loss': 0.012993106,\n"," 'Loss/regularization_loss': 0.13435991,\n"," 'Loss/total_loss': 0.20967315,\n"," 'learning_rate': 0.07976264}\n","I0422 15:36:25.355637 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.062320136,\n"," 'Loss/localization_loss': 0.012993106,\n"," 'Loss/regularization_loss': 0.13435991,\n"," 'Loss/total_loss': 0.20967315,\n"," 'learning_rate': 0.07976264}\n","INFO:tensorflow:Step 2800 per-step time 1.405s\n","I0422 15:38:45.821141 140003774904192 model_lib_v2.py:707] Step 2800 per-step time 1.405s\n","INFO:tensorflow:{'Loss/classification_loss': 0.0465953,\n"," 'Loss/localization_loss': 0.009675629,\n"," 'Loss/regularization_loss': 0.13361427,\n"," 'Loss/total_loss': 0.1898852,\n"," 'learning_rate': 0.07973392}\n","I0422 15:38:45.821552 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.0465953,\n"," 'Loss/localization_loss': 0.009675629,\n"," 'Loss/regularization_loss': 0.13361427,\n"," 'Loss/total_loss': 0.1898852,\n"," 'learning_rate': 0.07973392}\n","INFO:tensorflow:Step 2900 per-step time 1.417s\n","I0422 15:41:07.566440 140003774904192 model_lib_v2.py:707] Step 2900 per-step time 1.417s\n","INFO:tensorflow:{'Loss/classification_loss': 0.051498473,\n"," 'Loss/localization_loss': 0.014380321,\n"," 'Loss/regularization_loss': 0.13286549,\n"," 'Loss/total_loss': 0.19874428,\n"," 'learning_rate': 0.07970358}\n","I0422 15:41:07.566797 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.051498473,\n"," 'Loss/localization_loss': 0.014380321,\n"," 'Loss/regularization_loss': 0.13286549,\n"," 'Loss/total_loss': 0.19874428,\n"," 'learning_rate': 0.07970358}\n","INFO:tensorflow:Step 3000 per-step time 1.399s\n","I0422 15:43:27.507952 140003774904192 model_lib_v2.py:707] Step 3000 per-step time 1.399s\n","INFO:tensorflow:{'Loss/classification_loss': 0.043668937,\n"," 'Loss/localization_loss': 0.017400939,\n"," 'Loss/regularization_loss': 0.1321401,\n"," 'Loss/total_loss': 0.19320998,\n"," 'learning_rate': 0.0796716}\n","I0422 15:43:27.508313 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.043668937,\n"," 'Loss/localization_loss': 0.017400939,\n"," 'Loss/regularization_loss': 0.1321401,\n"," 'Loss/total_loss': 0.19320998,\n"," 'learning_rate': 0.0796716}\n","INFO:tensorflow:Step 3100 per-step time 1.416s\n","I0422 15:45:49.139751 140003774904192 model_lib_v2.py:707] Step 3100 per-step time 1.416s\n","INFO:tensorflow:{'Loss/classification_loss': 0.041507874,\n"," 'Loss/localization_loss': 0.011158802,\n"," 'Loss/regularization_loss': 0.13142213,\n"," 'Loss/total_loss': 0.18408881,\n"," 'learning_rate': 0.07963799}\n","I0422 15:45:49.140100 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.041507874,\n"," 'Loss/localization_loss': 0.011158802,\n"," 'Loss/regularization_loss': 0.13142213,\n"," 'Loss/total_loss': 0.18408881,\n"," 'learning_rate': 0.07963799}\n","INFO:tensorflow:Step 3200 per-step time 1.405s\n","I0422 15:48:09.674457 140003774904192 model_lib_v2.py:707] Step 3200 per-step time 1.405s\n","INFO:tensorflow:{'Loss/classification_loss': 0.058578342,\n"," 'Loss/localization_loss': 0.016012872,\n"," 'Loss/regularization_loss': 0.13069448,\n"," 'Loss/total_loss': 0.2052857,\n"," 'learning_rate': 0.07960275}\n","I0422 15:48:09.674830 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.058578342,\n"," 'Loss/localization_loss': 0.016012872,\n"," 'Loss/regularization_loss': 0.13069448,\n"," 'Loss/total_loss': 0.2052857,\n"," 'learning_rate': 0.07960275}\n","INFO:tensorflow:Step 3300 per-step time 1.407s\n","I0422 15:50:30.370004 140003774904192 model_lib_v2.py:707] Step 3300 per-step time 1.407s\n","INFO:tensorflow:{'Loss/classification_loss': 0.051574107,\n"," 'Loss/localization_loss': 0.011488891,\n"," 'Loss/regularization_loss': 0.12999693,\n"," 'Loss/total_loss': 0.19305992,\n"," 'learning_rate': 0.07956588}\n","I0422 15:50:30.370352 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.051574107,\n"," 'Loss/localization_loss': 0.011488891,\n"," 'Loss/regularization_loss': 0.12999693,\n"," 'Loss/total_loss': 0.19305992,\n"," 'learning_rate': 0.07956588}\n","INFO:tensorflow:Step 3400 per-step time 1.409s\n","I0422 15:52:51.222586 140003774904192 model_lib_v2.py:707] Step 3400 per-step time 1.409s\n","INFO:tensorflow:{'Loss/classification_loss': 0.04798174,\n"," 'Loss/localization_loss': 0.011582936,\n"," 'Loss/regularization_loss': 0.12928225,\n"," 'Loss/total_loss': 0.18884693,\n"," 'learning_rate': 0.079527386}\n","I0422 15:52:51.222941 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.04798174,\n"," 'Loss/localization_loss': 0.011582936,\n"," 'Loss/regularization_loss': 0.12928225,\n"," 'Loss/total_loss': 0.18884693,\n"," 'learning_rate': 0.079527386}\n","INFO:tensorflow:Step 3500 per-step time 1.411s\n","I0422 15:55:12.278837 140003774904192 model_lib_v2.py:707] Step 3500 per-step time 1.411s\n","INFO:tensorflow:{'Loss/classification_loss': 0.037682336,\n"," 'Loss/localization_loss': 0.00923576,\n"," 'Loss/regularization_loss': 0.12856208,\n"," 'Loss/total_loss': 0.17548017,\n"," 'learning_rate': 0.07948727}\n","I0422 15:55:12.279185 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.037682336,\n"," 'Loss/localization_loss': 0.00923576,\n"," 'Loss/regularization_loss': 0.12856208,\n"," 'Loss/total_loss': 0.17548017,\n"," 'learning_rate': 0.07948727}\n","INFO:tensorflow:Step 3600 per-step time 1.403s\n","I0422 15:57:32.625095 140003774904192 model_lib_v2.py:707] Step 3600 per-step time 1.403s\n","INFO:tensorflow:{'Loss/classification_loss': 0.02853882,\n"," 'Loss/localization_loss': 0.013051476,\n"," 'Loss/regularization_loss': 0.12785207,\n"," 'Loss/total_loss': 0.16944236,\n"," 'learning_rate': 0.079445526}\n","I0422 15:57:32.625496 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.02853882,\n"," 'Loss/localization_loss': 0.013051476,\n"," 'Loss/regularization_loss': 0.12785207,\n"," 'Loss/total_loss': 0.16944236,\n"," 'learning_rate': 0.079445526}\n","INFO:tensorflow:Step 3700 per-step time 1.409s\n","I0422 15:59:53.506395 140003774904192 model_lib_v2.py:707] Step 3700 per-step time 1.409s\n","INFO:tensorflow:{'Loss/classification_loss': 0.04016177,\n"," 'Loss/localization_loss': 0.011501777,\n"," 'Loss/regularization_loss': 0.12713869,\n"," 'Loss/total_loss': 0.17880224,\n"," 'learning_rate': 0.07940216}\n","I0422 15:59:53.506779 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.04016177,\n"," 'Loss/localization_loss': 0.011501777,\n"," 'Loss/regularization_loss': 0.12713869,\n"," 'Loss/total_loss': 0.17880224,\n"," 'learning_rate': 0.07940216}\n","INFO:tensorflow:Step 3800 per-step time 1.410s\n","I0422 16:02:14.524414 140003774904192 model_lib_v2.py:707] Step 3800 per-step time 1.410s\n","INFO:tensorflow:{'Loss/classification_loss': 0.05663595,\n"," 'Loss/localization_loss': 0.012655245,\n"," 'Loss/regularization_loss': 0.12643422,\n"," 'Loss/total_loss': 0.19572541,\n"," 'learning_rate': 0.079357184}\n","I0422 16:02:14.524758 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.05663595,\n"," 'Loss/localization_loss': 0.012655245,\n"," 'Loss/regularization_loss': 0.12643422,\n"," 'Loss/total_loss': 0.19572541,\n"," 'learning_rate': 0.079357184}\n","INFO:tensorflow:Step 3900 per-step time 1.409s\n","I0422 16:04:35.447817 140003774904192 model_lib_v2.py:707] Step 3900 per-step time 1.409s\n","INFO:tensorflow:{'Loss/classification_loss': 0.03760912,\n"," 'Loss/localization_loss': 0.021040196,\n"," 'Loss/regularization_loss': 0.12574191,\n"," 'Loss/total_loss': 0.18439123,\n"," 'learning_rate': 0.07931058}\n","I0422 16:04:35.448144 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.03760912,\n"," 'Loss/localization_loss': 0.021040196,\n"," 'Loss/regularization_loss': 0.12574191,\n"," 'Loss/total_loss': 0.18439123,\n"," 'learning_rate': 0.07931058}\n","INFO:tensorflow:Step 4000 per-step time 1.410s\n","I0422 16:06:56.400108 140003774904192 model_lib_v2.py:707] Step 4000 per-step time 1.410s\n","INFO:tensorflow:{'Loss/classification_loss': 0.04553363,\n"," 'Loss/localization_loss': 0.010513212,\n"," 'Loss/regularization_loss': 0.12504692,\n"," 'Loss/total_loss': 0.18109377,\n"," 'learning_rate': 0.07926236}\n","I0422 16:06:56.400428 140003774904192 model_lib_v2.py:708] {'Loss/classification_loss': 0.04553363,\n"," 'Loss/localization_loss': 0.010513212,\n"," 'Loss/regularization_loss': 0.12504692,\n"," 'Loss/total_loss': 0.18109377,\n"," 'learning_rate': 0.07926236}\n"]}],"source":["!{command}"]},{"cell_type":"markdown","source":["# 7. Evaluation"],"metadata":{"id":"ske1B_YJHn7k"}},{"cell_type":"code","source":["command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"],"metadata":{"id":"PC1e0asdHnou"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(command)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s0ga_20ZIJ5G","executionInfo":{"status":"ok","timestamp":1650492721752,"user_tz":240,"elapsed":17,"user":{"displayName":"NNM_","userId":"18288667490642199446"}},"outputId":"20d2bf90-bb80-4b5d-9e45-ce153d71e39a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["python tfod/models/research/object_detection/model_main_tf2.py --model_dir=tfod/workspace/models/my_ssd_mobilnet_v2 --pipeline_config_path=tfod/workspace/models/my_ssd_mobilnet_v2/pipeline.config --checkpoint_dir=tfod/workspace/models/my_ssd_mobilnet_v2\n"]}]},{"cell_type":"code","source":["!{command}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2F3ZWCQIIJvM","executionInfo":{"status":"ok","timestamp":1650492847742,"user_tz":240,"elapsed":124427,"user":{"displayName":"NNM_","userId":"18288667490642199446"}},"outputId":"c882ce05-e30c-4ba7-9820-be7eb1c7f374"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n","W0420 22:12:07.009545 139814644918144 model_lib_v2.py:1090] Forced number of epochs for all eval validations to be 1.\n","INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n","I0420 22:12:07.009758 139814644918144 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0420 22:12:07.009848 139814644918144 config_util.py:552] Maybe overwriting use_bfloat16: False\n","INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n","I0420 22:12:07.009944 139814644918144 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n","WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","W0420 22:12:07.010092 139814644918144 model_lib_v2.py:1111] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","2022-04-20 22:12:07.597760: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","INFO:tensorflow:Reading unweighted datasets: ['tfod/workspace/annotations/test.record']\n","I0420 22:12:07.745707 139814644918144 dataset_builder.py:162] Reading unweighted datasets: ['tfod/workspace/annotations/test.record']\n","INFO:tensorflow:Reading record datasets for input file: ['tfod/workspace/annotations/test.record']\n","I0420 22:12:07.745929 139814644918144 dataset_builder.py:79] Reading record datasets for input file: ['tfod/workspace/annotations/test.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0420 22:12:07.746038 139814644918144 dataset_builder.py:80] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0420 22:12:07.746117 139814644918144 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","W0420 22:12:07.747824 139814644918144 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0420 22:12:07.766664 139814644918144 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W0420 22:12:11.613114 139814644918144 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0420 22:12:12.695312 139814644918144 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","INFO:tensorflow:Waiting for new checkpoint at tfod/workspace/models/my_ssd_mobilnet_v2\n","I0420 22:12:15.081947 139814644918144 checkpoint_utils.py:136] Waiting for new checkpoint at tfod/workspace/models/my_ssd_mobilnet_v2\n","INFO:tensorflow:Found new checkpoint at tfod/workspace/models/my_ssd_mobilnet_v2/ckpt-5\n","I0420 22:12:15.082852 139814644918144 checkpoint_utils.py:145] Found new checkpoint at tfod/workspace/models/my_ssd_mobilnet_v2/ckpt-5\n","/usr/local/lib/python3.7/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0420 22:12:37.932855 139814644918144 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","INFO:tensorflow:Finished eval step 0\n","I0420 22:12:38.043678 139814644918144 model_lib_v2.py:966] Finished eval step 0\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","W0420 22:12:38.177172 139814644918144 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","INFO:tensorflow:Performing evaluation on 18 images.\n","I0420 22:12:41.705445 139814644918144 coco_evaluation.py:293] Performing evaluation on 18 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0420 22:12:41.705777 139814644918144 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0420 22:12:41.706944 139814644918144 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.04s).\n","Accumulating evaluation results...\n","DONE (t=0.03s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.550\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.698\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.643\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.552\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.735\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.735\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.735\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.735\n","INFO:tensorflow:Eval metrics at step 4000\n","I0420 22:12:41.786131 139814644918144 model_lib_v2.py:1015] Eval metrics at step 4000\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.550174\n","I0420 22:12:41.846601 139814644918144 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.550174\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.698144\n","I0420 22:12:41.847991 139814644918144 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.698144\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.643465\n","I0420 22:12:41.849405 139814644918144 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.643465\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): -1.000000\n","I0420 22:12:41.850866 139814644918144 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): -1.000000\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): -1.000000\n","I0420 22:12:41.852132 139814644918144 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): -1.000000\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.551907\n","I0420 22:12:41.853540 139814644918144 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.551907\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.735000\n","I0420 22:12:41.854791 139814644918144 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.735000\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.735000\n","I0420 22:12:41.855873 139814644918144 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.735000\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.735000\n","I0420 22:12:41.856930 139814644918144 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.735000\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n","I0420 22:12:41.858005 139814644918144 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): -1.000000\n","I0420 22:12:41.859075 139814644918144 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): -1.000000\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.735000\n","I0420 22:12:41.860167 139814644918144 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.735000\n","INFO:tensorflow:\t+ Loss/localization_loss: 0.106033\n","I0420 22:12:41.861151 139814644918144 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.106033\n","INFO:tensorflow:\t+ Loss/classification_loss: 0.616439\n","I0420 22:12:41.862157 139814644918144 model_lib_v2.py:1018] \t+ Loss/classification_loss: 0.616439\n","INFO:tensorflow:\t+ Loss/regularization_loss: 0.125794\n","I0420 22:12:41.863159 139814644918144 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.125794\n","INFO:tensorflow:\t+ Loss/total_loss: 0.848266\n","I0420 22:12:41.864165 139814644918144 model_lib_v2.py:1018] \t+ Loss/total_loss: 0.848266\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 312, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 258, in _run_main\n","    sys.exit(main(argv))\n","  File \"tfod/models/research/object_detection/model_main_tf2.py\", line 89, in main\n","    wait_interval=300, timeout=FLAGS.eval_timeout)\n","  File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 1137, in eval_continuously\n","    checkpoint_dir, timeout=timeout, min_interval_secs=wait_interval):\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 212, in checkpoints_iterator\n","    time.sleep(time_to_next_eval)\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"tfod/models/research/object_detection/model_main_tf2.py\", line 114, in <module>\n","    tf.compat.v1.app.run()\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/app.py\", line 36, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 312, in run\n","    _run_main(main, args)\n","KeyboardInterrupt\n"]}]},{"cell_type":"markdown","metadata":{"id":"rzlM4jt0pfDJ"},"source":["# 10. Freezing the Graph"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":156,"status":"ok","timestamp":1650643724529,"user":{"displayName":"NNM_","userId":"18288667490642199446"},"user_tz":240},"id":"n4olHB2npfDJ"},"outputs":[],"source":["FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":150,"status":"ok","timestamp":1650643725309,"user":{"displayName":"NNM_","userId":"18288667490642199446"},"user_tz":240},"id":"0AjO93QDpfDJ"},"outputs":[],"source":["command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":156,"status":"ok","timestamp":1650643726041,"user":{"displayName":"NNM_","userId":"18288667490642199446"},"user_tz":240},"id":"F6Lsp3tCpfDJ","outputId":"5a015146-1f7b-42d8-e886-7a84f3e9b095"},"outputs":[{"output_type":"stream","name":"stdout","text":["python tfod/models/research/object_detection/exporter_main_v2.py  --input_type=image_tensor --pipeline_config_path=tfod/workspace/models/my_ssd_mobilnet_v2/pipeline.config --trained_checkpoint_dir=tfod/workspace/models/my_ssd_mobilnet_v2 --output_directory=tfod/workspace/models/my_ssd_mobilnet_v2/export\n"]}],"source":["print(command)"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":50024,"status":"ok","timestamp":1650643776696,"user":{"displayName":"NNM_","userId":"18288667490642199446"},"user_tz":240},"id":"1Sw1ULgHpfDJ","outputId":"7608fb53-078d-4623-b55f-adf6e83d3187"},"outputs":[{"output_type":"stream","name":"stdout","text":["2022-04-22 16:08:54.402845: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n","Instructions for updating:\n","back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n","Instead of:\n","results = tf.map_fn(fn, elems, back_prop=False)\n","Use:\n","results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n","W0422 16:08:54.543400 139889658406784 deprecation.py:615] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n","Instructions for updating:\n","back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n","Instead of:\n","results = tf.map_fn(fn, elems, back_prop=False)\n","Use:\n","results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n","2022-04-22 16:09:10.522886: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f3a0002af10>, because it is not built.\n","W0422 16:09:13.813010 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f3a0002af10>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f398c0ad310>, because it is not built.\n","W0422 16:09:14.080787 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f398c0ad310>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3977551390>, because it is not built.\n","W0422 16:09:14.081008 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3977551390>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f39775519d0>, because it is not built.\n","W0422 16:09:14.081122 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f39775519d0>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f39776858d0>, because it is not built.\n","W0422 16:09:14.081220 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f39776858d0>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3977551b10>, because it is not built.\n","W0422 16:09:14.081318 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3977551b10>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f39775c48d0>, because it is not built.\n","W0422 16:09:14.081421 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f39775c48d0>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f39776a7ed0>, because it is not built.\n","W0422 16:09:14.081532 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f39776a7ed0>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3977a80c10>, because it is not built.\n","W0422 16:09:14.081641 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3977a80c10>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3977557d10>, because it is not built.\n","W0422 16:09:14.081743 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3977557d10>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f3977b8b150>, because it is not built.\n","W0422 16:09:14.081839 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f3977b8b150>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f39776643d0>, because it is not built.\n","W0422 16:09:14.081936 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f39776643d0>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3977684b10>, because it is not built.\n","W0422 16:09:14.082027 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3977684b10>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f398c0ade10>, because it is not built.\n","W0422 16:09:14.082118 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f398c0ade10>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f39775a6710>, because it is not built.\n","W0422 16:09:14.082212 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f39775a6710>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f39775a6610>, because it is not built.\n","W0422 16:09:14.082309 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f39775a6610>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3977621f50>, because it is not built.\n","W0422 16:09:14.082405 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3977621f50>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3977ea3950>, because it is not built.\n","W0422 16:09:14.082495 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3977ea3950>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f39776641d0>, because it is not built.\n","W0422 16:09:14.082602 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f39776641d0>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f39776c2ed0>, because it is not built.\n","W0422 16:09:14.082707 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f39776c2ed0>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f39775adc90>, because it is not built.\n","W0422 16:09:14.082810 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f39775adc90>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f398c0ade50>, because it is not built.\n","W0422 16:09:14.082907 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f398c0ade50>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f397756c2d0>, because it is not built.\n","W0422 16:09:14.083003 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f397756c2d0>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f39778a1150>, because it is not built.\n","W0422 16:09:14.083103 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f39778a1150>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3977731d10>, because it is not built.\n","W0422 16:09:14.083197 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3977731d10>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f397756c650>, because it is not built.\n","W0422 16:09:14.083287 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f397756c650>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3977623890>, because it is not built.\n","W0422 16:09:14.083381 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3977623890>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3977e35790>, because it is not built.\n","W0422 16:09:14.083471 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3977e35790>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f39776cd150>, because it is not built.\n","W0422 16:09:14.083573 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f39776cd150>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f39775379d0>, because it is not built.\n","W0422 16:09:14.083675 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f39775379d0>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f397753ba10>, because it is not built.\n","W0422 16:09:14.083766 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f397753ba10>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f39777bf250>, because it is not built.\n","W0422 16:09:14.083874 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f39777bf250>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f397754a850>, because it is not built.\n","W0422 16:09:14.083979 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f397754a850>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f39776713d0>, because it is not built.\n","W0422 16:09:14.084074 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f39776713d0>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3977c04b10>, because it is not built.\n","W0422 16:09:14.084172 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3977c04b10>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f39774cad10>, because it is not built.\n","W0422 16:09:14.084269 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f39774cad10>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3977599450>, because it is not built.\n","W0422 16:09:14.084367 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3977599450>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f398c0ade90>, because it is not built.\n","W0422 16:09:14.084481 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f398c0ade90>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3977569090>, because it is not built.\n","W0422 16:09:14.084591 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f3977569090>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3977569610>, because it is not built.\n","W0422 16:09:14.084699 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f3977569610>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f39777624d0>, because it is not built.\n","W0422 16:09:14.084797 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f39777624d0>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f39778a1190>, because it is not built.\n","W0422 16:09:14.084894 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f39778a1190>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f397760c390>, because it is not built.\n","W0422 16:09:14.084994 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f397760c390>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f397760c410>, because it is not built.\n","W0422 16:09:14.085094 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f397760c410>, because it is not built.\n","WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f397760cb10>, because it is not built.\n","W0422 16:09:14.124346 139889658406784 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f397760cb10>, because it is not built.\n","W0422 16:09:29.890974 139889658406784 save.py:265] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 104). These functions will not be directly callable after loading.\n","INFO:tensorflow:Assets written to: tfod/workspace/models/my_ssd_mobilnet_v2/export/saved_model/assets\n","I0422 16:09:35.351464 139889658406784 builder_impl.py:780] Assets written to: tfod/workspace/models/my_ssd_mobilnet_v2/export/saved_model/assets\n","INFO:tensorflow:Writing pipeline config file to tfod/workspace/models/my_ssd_mobilnet_v2/export/pipeline.config\n","I0422 16:09:35.907727 139889658406784 config_util.py:254] Writing pipeline config file to tfod/workspace/models/my_ssd_mobilnet_v2/export/pipeline.config\n"]}],"source":["!{command}"]},{"cell_type":"markdown","metadata":{"id":"5NQqZRdA21Uc"},"source":["# 13. Zip and Export Models "]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":6785,"status":"ok","timestamp":1650644735571,"user":{"displayName":"NNM_","userId":"18288667490642199446"},"user_tz":240},"id":"tTVTGCQp2ZJJ"},"outputs":[],"source":["# download the following zip file\n","!tar -czf models.tar.gz {paths['CHECKPOINT_PATH']}"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"tfod_main.ipynb","provenance":[]},"interpreter":{"hash":"56367c02e77b3cce5b23b68e6af8cef76d756dc6a283f6e5aee95bb15d2a4fea"},"kernelspec":{"display_name":"tfod","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"}},"nbformat":4,"nbformat_minor":0}